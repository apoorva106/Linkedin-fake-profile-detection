{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0123a4-0e1a-49c6-b14b-41553a7e269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 18:33:43.966671: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-03 18:33:44.066405: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-03 18:33:44.591520: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-11-03 18:33:44.591576: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-11-03 18:33:44.591581: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae027418-2a84-4982-a36e-85c28b96d3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intro</th>\n",
       "      <th>Full Name</th>\n",
       "      <th>Workplace</th>\n",
       "      <th>Location</th>\n",
       "      <th>Connections</th>\n",
       "      <th>Photo</th>\n",
       "      <th>Followers</th>\n",
       "      <th>About</th>\n",
       "      <th>Experiences</th>\n",
       "      <th>Number of Experiences</th>\n",
       "      <th>...</th>\n",
       "      <th>Number of Scores</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Number of Languages</th>\n",
       "      <th>Organizations</th>\n",
       "      <th>Number of Organizations</th>\n",
       "      <th>Interests</th>\n",
       "      <th>Number of Interests</th>\n",
       "      <th>Activities</th>\n",
       "      <th>Number of Activities</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'Full Name': 'chenxia (polly) Pei', 'Workplac...</td>\n",
       "      <td>chenxia (polly) Pei</td>\n",
       "      <td>Jiangsu Junyao mainly offer services to cement...</td>\n",
       "      <td>Wuxi, Jiangsu, China</td>\n",
       "      <td>500</td>\n",
       "      <td>No</td>\n",
       "      <td>717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0': {'Role': 'Sales', 'Workplace': 'Jiangsu ...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': {'Interest': 'Trina Solar', 'ID': '69648...</td>\n",
       "      <td>4</td>\n",
       "      <td>{'chenxia-pei-80177594': {'Full Name': 'chenxi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'Full Name': 'NEHA CHANDOK', 'Workplace': 'So...</td>\n",
       "      <td>NEHA CHANDOK</td>\n",
       "      <td>Software Analyst</td>\n",
       "      <td>Noida, Uttar Pradesh, India</td>\n",
       "      <td>500</td>\n",
       "      <td>No</td>\n",
       "      <td>1340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0': {'Role': 'Software Analyst', 'Workplace'...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Language 0': 'Bangla', 'Language 1': 'Englis...</td>\n",
       "      <td>3</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': {'Interest': 'Mohamed El-Erian', 'ID': '...</td>\n",
       "      <td>8</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'Full Name': 'Mounika Mungamuri', 'Workplace'...</td>\n",
       "      <td>Mounika Mungamuri</td>\n",
       "      <td>Senior Consultant at Infosys</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0': {'Role': 'Senior Consultant', 'Workplace...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'Full Name': 'Katarina Djuric', 'Workplace': ...</td>\n",
       "      <td>Katarina Djuric</td>\n",
       "      <td>--</td>\n",
       "      <td>Belgrade, Serbia</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0': {'Role': 'Instructor', 'Workplace': 'GE'...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': {'Interest': 'GE', 'ID': '1015', 'Catego...</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'Full Name': 'Rachel Lally', 'Workplace': '--...</td>\n",
       "      <td>Rachel Lally</td>\n",
       "      <td>--</td>\n",
       "      <td>Dublin, County Dublin, Ireland</td>\n",
       "      <td>61</td>\n",
       "      <td>Yes</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0': {'Role': 'Bartender', 'Workplace': \"O'Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': {'Interest': 'Richard Branson', 'ID': 'r...</td>\n",
       "      <td>3</td>\n",
       "      <td>{'garyltravis': {'Full Name': 'Gary Travis', '...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>{'Full Name': 'Emily Williams', 'Workplace': \"...</td>\n",
       "      <td>Emily Williams</td>\n",
       "      <td>Market Research Analyst at L'Oreal</td>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>106</td>\n",
       "      <td>No</td>\n",
       "      <td>717</td>\n",
       "      <td>{}</td>\n",
       "      <td>Market Research Analyst Elizabeth Arden Jan 20...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>3</td>\n",
       "      <td>{}</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>{'Full Name': 'Sarah Johnson', 'Workplace': 'D...</td>\n",
       "      <td>Sarah Johnson</td>\n",
       "      <td>Director of Marketing Strategy at Acme Inc.</td>\n",
       "      <td>San Francisco, California</td>\n",
       "      <td>102</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>{}</td>\n",
       "      <td>Director of Marketing Acme Inc. January 2018-P...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>5</td>\n",
       "      <td>{}</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>{'Full Name': 'Sarah Johnson', 'Workplace': 'M...</td>\n",
       "      <td>Sarah Johnson</td>\n",
       "      <td>Manager at Acme Inc.</td>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>435</td>\n",
       "      <td>No</td>\n",
       "      <td>10</td>\n",
       "      <td>A results-driven and experienced professional ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>6</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>{'Full Name': 'Emma Williams', 'Workplace': 'M...</td>\n",
       "      <td>Emma Williams</td>\n",
       "      <td>Manager and Director at ABC Inc.</td>\n",
       "      <td>Seattle, Washington</td>\n",
       "      <td>280</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>With over 10 years of experience in operations...</td>\n",
       "      <td>Operations Manager ABC Inc. January 2015- Pres...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>English Spanish</td>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>4</td>\n",
       "      <td>{}</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>{'Full Name': 'Rachel Johnson', 'Workplace': '...</td>\n",
       "      <td>Rachel Johnson</td>\n",
       "      <td>Market Development Manager at ABC Inc.</td>\n",
       "      <td>Dhaka, Bangladesh</td>\n",
       "      <td>102</td>\n",
       "      <td>No</td>\n",
       "      <td>26</td>\n",
       "      <td>{}</td>\n",
       "      <td>Market Development Manager ABC Inc. January 20...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Intro            Full Name  \\\n",
       "0     {'Full Name': 'chenxia (polly) Pei', 'Workplac...  chenxia (polly) Pei   \n",
       "1     {'Full Name': 'NEHA CHANDOK', 'Workplace': 'So...         NEHA CHANDOK   \n",
       "2     {'Full Name': 'Mounika Mungamuri', 'Workplace'...    Mounika Mungamuri   \n",
       "3     {'Full Name': 'Katarina Djuric', 'Workplace': ...      Katarina Djuric   \n",
       "4     {'Full Name': 'Rachel Lally', 'Workplace': '--...         Rachel Lally   \n",
       "...                                                 ...                  ...   \n",
       "3595  {'Full Name': 'Emily Williams', 'Workplace': \"...       Emily Williams   \n",
       "3596  {'Full Name': 'Sarah Johnson', 'Workplace': 'D...        Sarah Johnson   \n",
       "3597  {'Full Name': 'Sarah Johnson', 'Workplace': 'M...        Sarah Johnson   \n",
       "3598  {'Full Name': 'Emma Williams', 'Workplace': 'M...        Emma Williams   \n",
       "3599  {'Full Name': 'Rachel Johnson', 'Workplace': '...       Rachel Johnson   \n",
       "\n",
       "                                              Workplace  \\\n",
       "0     Jiangsu Junyao mainly offer services to cement...   \n",
       "1                                      Software Analyst   \n",
       "2                          Senior Consultant at Infosys   \n",
       "3                                                    --   \n",
       "4                                                    --   \n",
       "...                                                 ...   \n",
       "3595                 Market Research Analyst at L'Oreal   \n",
       "3596        Director of Marketing Strategy at Acme Inc.   \n",
       "3597                               Manager at Acme Inc.   \n",
       "3598                   Manager and Director at ABC Inc.   \n",
       "3599             Market Development Manager at ABC Inc.   \n",
       "\n",
       "                            Location  Connections Photo  Followers  \\\n",
       "0               Wuxi, Jiangsu, China          500    No        717   \n",
       "1        Noida, Uttar Pradesh, India          500    No       1340   \n",
       "2        Hyderabad, Telangana, India            7   Yes          7   \n",
       "3                   Belgrade, Serbia            0   Yes          0   \n",
       "4     Dublin, County Dublin, Ireland           61   Yes         61   \n",
       "...                              ...          ...   ...        ...   \n",
       "3595         New York City, New York          106    No        717   \n",
       "3596       San Francisco, California          102    No          6   \n",
       "3597         New York City, New York          435    No         10   \n",
       "3598             Seattle, Washington          280    No         34   \n",
       "3599               Dhaka, Bangladesh          102    No         26   \n",
       "\n",
       "                                                  About  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "3595                                                 {}   \n",
       "3596                                                 {}   \n",
       "3597  A results-driven and experienced professional ...   \n",
       "3598  With over 10 years of experience in operations...   \n",
       "3599                                                 {}   \n",
       "\n",
       "                                            Experiences  \\\n",
       "0     {'0': {'Role': 'Sales', 'Workplace': 'Jiangsu ...   \n",
       "1     {'0': {'Role': 'Software Analyst', 'Workplace'...   \n",
       "2     {'0': {'Role': 'Senior Consultant', 'Workplace...   \n",
       "3     {'0': {'Role': 'Instructor', 'Workplace': 'GE'...   \n",
       "4     {'0': {'Role': 'Bartender', 'Workplace': \"O'Su...   \n",
       "...                                                 ...   \n",
       "3595  Market Research Analyst Elizabeth Arden Jan 20...   \n",
       "3596  Director of Marketing Acme Inc. January 2018-P...   \n",
       "3597                                                 {}   \n",
       "3598  Operations Manager ABC Inc. January 2015- Pres...   \n",
       "3599  Market Development Manager ABC Inc. January 20...   \n",
       "\n",
       "      Number of Experiences  ... Number of Scores  \\\n",
       "0                         2  ...                0   \n",
       "1                         1  ...                0   \n",
       "2                         2  ...                0   \n",
       "3                         1  ...                0   \n",
       "4                         1  ...                1   \n",
       "...                     ...  ...              ...   \n",
       "3595                      3  ...                0   \n",
       "3596                      5  ...                0   \n",
       "3597                      0  ...                0   \n",
       "3598                      1  ...                0   \n",
       "3599                      5  ...                0   \n",
       "\n",
       "                                              Languages Number of Languages  \\\n",
       "0                                                    {}                   0   \n",
       "1     {'Language 0': 'Bangla', 'Language 1': 'Englis...                   3   \n",
       "2                                                    {}                   0   \n",
       "3                                                    {}                   0   \n",
       "4                                                    {}                   0   \n",
       "...                                                 ...                 ...   \n",
       "3595                                                 {}                   0   \n",
       "3596                                                 {}                   0   \n",
       "3597                                                 {}                   0   \n",
       "3598                                    English Spanish                   2   \n",
       "3599                                                 {}                   0   \n",
       "\n",
       "      Organizations Number of Organizations  \\\n",
       "0                {}                       0   \n",
       "1                {}                       0   \n",
       "2                {}                       0   \n",
       "3                {}                       0   \n",
       "4                {}                       0   \n",
       "...             ...                     ...   \n",
       "3595             {}                       0   \n",
       "3596             {}                       0   \n",
       "3597             {}                       0   \n",
       "3598             {}                       0   \n",
       "3599             {}                       0   \n",
       "\n",
       "                                              Interests Number of Interests  \\\n",
       "0     {'0': {'Interest': 'Trina Solar', 'ID': '69648...                   4   \n",
       "1     {'0': {'Interest': 'Mohamed El-Erian', 'ID': '...                   8   \n",
       "2                                                    {}                   0   \n",
       "3     {'0': {'Interest': 'GE', 'ID': '1015', 'Catego...                   1   \n",
       "4     {'0': {'Interest': 'Richard Branson', 'ID': 'r...                   3   \n",
       "...                                                 ...                 ...   \n",
       "3595                                                 {}                   3   \n",
       "3596                                                 {}                   5   \n",
       "3597                                                 {}                   6   \n",
       "3598                                                 {}                   4   \n",
       "3599                                                 {}                   2   \n",
       "\n",
       "                                             Activities Number of Activities  \\\n",
       "0     {'chenxia-pei-80177594': {'Full Name': 'chenxi...                    1   \n",
       "1                                                    {}                    0   \n",
       "2                                                    {}                    0   \n",
       "3                                                    {}                    0   \n",
       "4     {'garyltravis': {'Full Name': 'Gary Travis', '...                    6   \n",
       "...                                                 ...                  ...   \n",
       "3595                                                 {}                    4   \n",
       "3596                                                 {}                    3   \n",
       "3597                                                 {}                    0   \n",
       "3598                                                 {}                    4   \n",
       "3599                                                 {}                   10   \n",
       "\n",
       "      Label  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "...     ...  \n",
       "3595     11  \n",
       "3596     11  \n",
       "3597     11  \n",
       "3598     11  \n",
       "3599     11  \n",
       "\n",
       "[3600 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read from CSV instead of pickle\n",
    "dataset = pd.read_csv('cleaned_profiles.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9288087a-d93b-442b-923e-dec9ca0f7e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (3600, 768)\n",
      "Shape of y: (3600,)\n",
      "Accuracy of Random_forest Classifier: 0.9389\n",
      "Accuracy of Logistic_regression Classifier: 0.9083\n",
      "Accuracy of Svc Classifier: 0.8500\n",
      "Accuracy of Knn Classifier: 0.9250\n",
      "Accuracy of Xgboost Classifier: 0.9472\n",
      "Accuracy of Catboost Classifier: 0.9444\n",
      "\n",
      "Number of training samples: 840\n",
      "Number of testing samples: 360\n",
      "Total samples: 1200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Load the BERT embeddings\n",
    "emb = pd.read_csv('bert_numerical_STE_tokenised_D_NEW.csv')\n",
    "\n",
    "# Prepare the features (X) and labels (y)\n",
    "X = emb\n",
    "dataset.loc[dataset['Label'].isin([10, 11]), 'Label'] = 1\n",
    "y = dataset[\"Label\"]\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "# Function to train and evaluate classifiers\n",
    "def train_and_evaluate_classifier(X, y, classifier, test_size=0.3, random_state=42):\n",
    "    # Splitting the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=360, train_size=840, stratify=y, random_state=42)\n",
    "    \n",
    "    # Initialize the classifier based on the input string\n",
    "    if classifier == 'random_forest':\n",
    "        clf = RandomForestClassifier(random_state=random_state)\n",
    "    elif classifier == 'logistic_regression':\n",
    "        clf = LogisticRegression(random_state=random_state)\n",
    "    elif classifier == 'svc':\n",
    "        clf = SVC(random_state=random_state)\n",
    "    elif classifier == 'knn':\n",
    "        clf = KNeighborsClassifier()\n",
    "    elif classifier == 'xgboost':\n",
    "        clf = XGBClassifier(random_state=random_state)\n",
    "    elif classifier == 'catboost':\n",
    "        clf = CatBoostClassifier(random_state=random_state, verbose=False)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid classifier type.\")\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels for the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy of the classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# List of classifiers to test\n",
    "classifiers = ['random_forest', 'logistic_regression', 'svc', 'knn', 'xgboost', 'catboost']\n",
    "\n",
    "# Set a common random state for reproducibility\n",
    "random_state = 42\n",
    "\n",
    "# Iterate over each classifier and call the function\n",
    "for classifier in classifiers:\n",
    "    accuracy = train_and_evaluate_classifier(X, y, classifier, random_state=random_state)\n",
    "    print(f\"Accuracy of {classifier.capitalize()} Classifier: {accuracy:.4f}\")\n",
    "\n",
    "# Print the number of samples used for training and testing\n",
    "print(f\"\\nNumber of training samples: 840\")\n",
    "print(f\"Number of testing samples: 360\")\n",
    "print(f\"Total samples: 1200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "affd423e-cb57-46f4-87f2-a5dff7a6d14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (3600, 768)\n",
      "Shape of y: (3600,)\n"
     ]
    }
   ],
   "source": [
    "emb = pd.read_csv('bert_numerical_STE_tokenised_D_NEW.csv')\n",
    "\n",
    "# Prepare the features (X) and labels (y)\n",
    "X = emb\n",
    "dataset.loc[dataset['Label'].isin([10, 11]), 'Label'] = 1\n",
    "y = dataset[\"Label\"]\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbec82c3-4b68-4314-88b1-e9d126f9804e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter optimization at 00:41:59\n",
      "Number of training samples: 840\n",
      "Number of testing samples: 360\n",
      "Total samples: 1200\n",
      "\n",
      "Genetic Algorithm Optimization\n",
      "\n",
      "Starting Genetic Algorithm at 00:41:59\n",
      "\n",
      "Preparing data...\n",
      "Input shape: X=(3600, 768), y=(3600,)\n",
      "After split: X_train=(840, 768), X_test=(360, 768)\n",
      "Data scaling completed\n",
      "\n",
      "GA Configuration:\n",
      "Population size: 50\n",
      "Number of generations: 10\n",
      "Starting evolution...\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t50    \t0.943444\t0.922222\t0.963889\t0.0112046\n",
      "1  \t33    \t0.951389\t0.922222\t0.963889\t0.0093994\n",
      "2  \t33    \t0.954889\t0.936111\t0.963889\t0.00639637\n",
      "3  \t24    \t0.958722\t0.944444\t0.963889\t0.00535787\n",
      "4  \t39    \t0.960167\t0.941667\t0.963889\t0.00495691\n",
      "5  \t27    \t0.962111\t0.941667\t0.963889\t0.00447076\n",
      "6  \t28    \t0.963222\t0.955556\t0.963889\t0.00196889\n",
      "7  \t33    \t0.961667\t0.9     \t0.963889\t0.00936239\n",
      "8  \t30    \t0.961889\t0.888889\t0.963889\t0.0105853 \n",
      "9  \t35    \t0.963889\t0.963889\t0.963889\t0         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:47:53,851] A new study created in memory with name: no-name-9365dc07-914c-4f0b-9d66-fe257dc24c31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \t31    \t0.963722\t0.955556\t0.963889\t0.00116667\n",
      "\n",
      "GA completed at 00:47:53\n",
      "Total duration: 0:05:54.273232\n",
      "\n",
      "Best parameters (Genetic Algorithm): {'depth': 1, 'learning_rate': 0.18367011746081183, 'iterations': 489, 'l2_leaf_reg': 5.903845378061958, 'border_count': 204}\n",
      "Best accuracy (Genetic Algorithm): 0.9638888888888889\n",
      "\n",
      "Bayesian Optimization\n",
      "\n",
      "Starting Bayesian Optimization at 00:47:53\n",
      "\n",
      "Preparing data...\n",
      "Input shape: X=(3600, 768), y=(3600,)\n",
      "After split: X_train=(840, 768), X_test=(360, 768)\n",
      "Data scaling completed\n",
      "Running Bayesian Optimization for 50 trials...\n",
      "\n",
      "Trial 1/50 started at 00:47:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:47:54,644] Trial 0 finished with value: 0.9444444444444444 and parameters: {'depth': 6, 'learning_rate': 0.012497741501685387, 'iterations': 64, 'l2_leaf_reg': 0.0002910376589038683, 'border_count': 69}. Best is trial 0 with value: 0.9444444444444444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 results:\n",
      "Accuracy: 0.9444\n",
      "Best accuracy so far: 0.9444\n",
      "Trial duration: 0:00:00.790581\n",
      "Average trial duration: 0.79 seconds\n",
      "Estimated time remaining: 38.74 seconds\n",
      "\n",
      "Trial 2/50 started at 00:47:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:47:57,819] Trial 1 finished with value: 0.9527777777777777 and parameters: {'depth': 3, 'learning_rate': 0.01660939198917586, 'iterations': 579, 'l2_leaf_reg': 0.042036681276406807, 'border_count': 133}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 results:\n",
      "Accuracy: 0.9528\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:03.171996\n",
      "Average trial duration: 1.98 seconds\n",
      "Estimated time remaining: 95.10 seconds\n",
      "\n",
      "Trial 3/50 started at 00:47:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:47:58,814] Trial 2 finished with value: 0.9277777777777778 and parameters: {'depth': 7, 'learning_rate': 0.17185815831266024, 'iterations': 260, 'l2_leaf_reg': 0.005131966907780447, 'border_count': 176}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 results:\n",
      "Accuracy: 0.9278\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:00.991892\n",
      "Average trial duration: 1.65 seconds\n",
      "Estimated time remaining: 77.62 seconds\n",
      "\n",
      "Trial 4/50 started at 00:47:58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:10,106] Trial 3 finished with value: 0.9277777777777778 and parameters: {'depth': 10, 'learning_rate': 0.03146297503297142, 'iterations': 516, 'l2_leaf_reg': 0.19630431751536837, 'border_count': 138}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 results:\n",
      "Accuracy: 0.9278\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:11.290418\n",
      "Average trial duration: 4.06 seconds\n",
      "Estimated time remaining: 186.82 seconds\n",
      "\n",
      "Trial 5/50 started at 00:48:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:11,683] Trial 4 finished with value: 0.9333333333333333 and parameters: {'depth': 1, 'learning_rate': 0.011378722527744703, 'iterations': 704, 'l2_leaf_reg': 1.014627477543471e-05, 'border_count': 96}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 results:\n",
      "Accuracy: 0.9333\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:01.572078\n",
      "Average trial duration: 3.56 seconds\n",
      "Estimated time remaining: 160.35 seconds\n",
      "\n",
      "Trial 6/50 started at 00:48:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:13,226] Trial 5 finished with value: 0.925 and parameters: {'depth': 6, 'learning_rate': 0.001562172883863319, 'iterations': 84, 'l2_leaf_reg': 0.0028883590538526242, 'border_count': 247}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 results:\n",
      "Accuracy: 0.9250\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:01.542235\n",
      "Average trial duration: 3.23 seconds\n",
      "Estimated time remaining: 141.97 seconds\n",
      "\n",
      "Trial 7/50 started at 00:48:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:19,516] Trial 6 finished with value: 0.9472222222222222 and parameters: {'depth': 4, 'learning_rate': 0.00565800888015955, 'iterations': 823, 'l2_leaf_reg': 0.7785606178442693, 'border_count': 198}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 results:\n",
      "Accuracy: 0.9472\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:06.287213\n",
      "Average trial duration: 3.66 seconds\n",
      "Estimated time remaining: 157.54 seconds\n",
      "\n",
      "Trial 8/50 started at 00:48:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:20,527] Trial 7 finished with value: 0.95 and parameters: {'depth': 1, 'learning_rate': 0.08338708697593158, 'iterations': 633, 'l2_leaf_reg': 0.0013927677283338987, 'border_count': 177}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 results:\n",
      "Accuracy: 0.9500\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:01.009906\n",
      "Average trial duration: 3.33 seconds\n",
      "Estimated time remaining: 139.95 seconds\n",
      "\n",
      "Trial 9/50 started at 00:48:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:26,042] Trial 8 finished with value: 0.9444444444444444 and parameters: {'depth': 5, 'learning_rate': 0.004710508346116758, 'iterations': 583, 'l2_leaf_reg': 0.28833339166683425, 'border_count': 69}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 results:\n",
      "Accuracy: 0.9444\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:05.512864\n",
      "Average trial duration: 3.57 seconds\n",
      "Estimated time remaining: 146.55 seconds\n",
      "\n",
      "Trial 10/50 started at 00:48:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:28,571] Trial 9 finished with value: 0.925 and parameters: {'depth': 3, 'learning_rate': 0.002132034760813732, 'iterations': 426, 'l2_leaf_reg': 4.679607054791536, 'border_count': 136}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 results:\n",
      "Accuracy: 0.9250\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:02.526979\n",
      "Average trial duration: 3.47 seconds\n",
      "Estimated time remaining: 138.78 seconds\n",
      "\n",
      "Trial 11/50 started at 00:48:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:30,583] Trial 10 finished with value: 0.9388888888888889 and parameters: {'depth': 8, 'learning_rate': 0.042801783333157505, 'iterations': 950, 'l2_leaf_reg': 0.0781131714975699, 'border_count': 41}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 results:\n",
      "Accuracy: 0.9389\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:02.011061\n",
      "Average trial duration: 3.34 seconds\n",
      "Estimated time remaining: 130.14 seconds\n",
      "\n",
      "Trial 12/50 started at 00:48:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:31,282] Trial 11 finished with value: 0.95 and parameters: {'depth': 1, 'learning_rate': 0.13627676310872594, 'iterations': 684, 'l2_leaf_reg': 0.0003320691607635605, 'border_count': 187}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 results:\n",
      "Accuracy: 0.9500\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:00.697334\n",
      "Average trial duration: 3.12 seconds\n",
      "Estimated time remaining: 118.45 seconds\n",
      "\n",
      "Trial 13/50 started at 00:48:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:32,334] Trial 12 finished with value: 0.9472222222222222 and parameters: {'depth': 3, 'learning_rate': 0.06539981536487985, 'iterations': 315, 'l2_leaf_reg': 0.01872404843719354, 'border_count': 235}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 results:\n",
      "Accuracy: 0.9472\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:01.049691\n",
      "Average trial duration: 2.96 seconds\n",
      "Estimated time remaining: 109.45 seconds\n",
      "\n",
      "Trial 14/50 started at 00:48:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:33,229] Trial 13 finished with value: 0.9444444444444444 and parameters: {'depth': 2, 'learning_rate': 0.07788322112934735, 'iterations': 684, 'l2_leaf_reg': 0.0003785080008231165, 'border_count': 113}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 results:\n",
      "Accuracy: 0.9444\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:00.893328\n",
      "Average trial duration: 2.81 seconds\n",
      "Estimated time remaining: 101.18 seconds\n",
      "\n",
      "Trial 15/50 started at 00:48:33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:35,928] Trial 14 finished with value: 0.9527777777777777 and parameters: {'depth': 3, 'learning_rate': 0.021957482931847586, 'iterations': 851, 'l2_leaf_reg': 0.0017282396319864316, 'border_count': 158}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 results:\n",
      "Accuracy: 0.9528\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:02.698072\n",
      "Average trial duration: 2.80 seconds\n",
      "Estimated time remaining: 98.11 seconds\n",
      "\n",
      "Trial 16/50 started at 00:48:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:38,425] Trial 15 finished with value: 0.95 and parameters: {'depth': 4, 'learning_rate': 0.022780076248611326, 'iterations': 975, 'l2_leaf_reg': 0.028317943170436254, 'border_count': 158}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 results:\n",
      "Accuracy: 0.9500\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:02.494765\n",
      "Average trial duration: 2.78 seconds\n",
      "Estimated time remaining: 94.65 seconds\n",
      "\n",
      "Trial 17/50 started at 00:48:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:43,236] Trial 16 finished with value: 0.9472222222222222 and parameters: {'depth': 3, 'learning_rate': 0.005774983597751603, 'iterations': 823, 'l2_leaf_reg': 1.0830116133146856e-05, 'border_count': 216}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 results:\n",
      "Accuracy: 0.9472\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:04.810399\n",
      "Average trial duration: 2.90 seconds\n",
      "Estimated time remaining: 95.80 seconds\n",
      "\n",
      "Trial 18/50 started at 00:48:43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:45,367] Trial 17 finished with value: 0.95 and parameters: {'depth': 4, 'learning_rate': 0.016234913942497157, 'iterations': 840, 'l2_leaf_reg': 5.4984616710932465e-05, 'border_count': 112}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 results:\n",
      "Accuracy: 0.9500\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:02.129053\n",
      "Average trial duration: 2.86 seconds\n",
      "Estimated time remaining: 91.52 seconds\n",
      "\n",
      "Trial 19/50 started at 00:48:45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:47,035] Trial 18 finished with value: 0.9333333333333333 and parameters: {'depth': 2, 'learning_rate': 0.008490037403785265, 'iterations': 396, 'l2_leaf_reg': 1.9048278277602742, 'border_count': 153}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 results:\n",
      "Accuracy: 0.9333\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:01.665751\n",
      "Average trial duration: 2.80 seconds\n",
      "Estimated time remaining: 86.71 seconds\n",
      "\n",
      "Trial 20/50 started at 00:48:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:47,541] Trial 19 finished with value: 0.9416666666666667 and parameters: {'depth': 5, 'learning_rate': 0.24842816290318537, 'iterations': 771, 'l2_leaf_reg': 0.012783977149660779, 'border_count': 124}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 results:\n",
      "Accuracy: 0.9417\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:00.504321\n",
      "Average trial duration: 2.68 seconds\n",
      "Estimated time remaining: 80.47 seconds\n",
      "\n",
      "Trial 21/50 started at 00:48:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:48,387] Trial 20 finished with value: 0.9111111111111111 and parameters: {'depth': 2, 'learning_rate': 0.002924495298250755, 'iterations': 194, 'l2_leaf_reg': 0.0013018762072072201, 'border_count': 212}. Best is trial 1 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 results:\n",
      "Accuracy: 0.9111\n",
      "Best accuracy so far: 0.9528\n",
      "Trial duration: 0:00:00.843963\n",
      "Average trial duration: 2.59 seconds\n",
      "Estimated time remaining: 75.25 seconds\n",
      "\n",
      "Trial 22/50 started at 00:48:48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:49,739] Trial 21 finished with value: 0.9583333333333334 and parameters: {'depth': 1, 'learning_rate': 0.0575331734547721, 'iterations': 588, 'l2_leaf_reg': 0.001412348446111067, 'border_count': 162}. Best is trial 21 with value: 0.9583333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 results:\n",
      "Accuracy: 0.9583\n",
      "Best accuracy so far: 0.9583\n",
      "Trial duration: 0:00:01.350061\n",
      "Average trial duration: 2.54 seconds\n",
      "Estimated time remaining: 71.07 seconds\n",
      "\n",
      "Trial 23/50 started at 00:48:49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:51,460] Trial 22 finished with value: 0.9555555555555556 and parameters: {'depth': 2, 'learning_rate': 0.03475124859257218, 'iterations': 531, 'l2_leaf_reg': 0.06786475697169791, 'border_count': 161}. Best is trial 21 with value: 0.9583333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23 results:\n",
      "Accuracy: 0.9556\n",
      "Best accuracy so far: 0.9583\n",
      "Trial duration: 0:00:01.719209\n",
      "Average trial duration: 2.50 seconds\n",
      "Estimated time remaining: 67.57 seconds\n",
      "\n",
      "Trial 24/50 started at 00:48:51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:52,915] Trial 23 finished with value: 0.95 and parameters: {'depth': 2, 'learning_rate': 0.04474091884508138, 'iterations': 549, 'l2_leaf_reg': 0.05370011048007941, 'border_count': 91}. Best is trial 21 with value: 0.9583333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 results:\n",
      "Accuracy: 0.9500\n",
      "Best accuracy so far: 0.9583\n",
      "Trial duration: 0:00:01.453491\n",
      "Average trial duration: 2.46 seconds\n",
      "Estimated time remaining: 63.93 seconds\n",
      "\n",
      "Trial 25/50 started at 00:48:52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:53,950] Trial 24 finished with value: 0.9416666666666667 and parameters: {'depth': 1, 'learning_rate': 0.03189140208745452, 'iterations': 444, 'l2_leaf_reg': 0.11817229392679483, 'border_count': 165}. Best is trial 21 with value: 0.9583333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 results:\n",
      "Accuracy: 0.9417\n",
      "Best accuracy so far: 0.9583\n",
      "Trial duration: 0:00:01.033790\n",
      "Average trial duration: 2.40 seconds\n",
      "Estimated time remaining: 60.05 seconds\n",
      "\n",
      "Trial 26/50 started at 00:48:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:55,380] Trial 25 finished with value: 0.9527777777777777 and parameters: {'depth': 2, 'learning_rate': 0.06266074023271824, 'iterations': 485, 'l2_leaf_reg': 0.006995367234573243, 'border_count': 134}. Best is trial 21 with value: 0.9583333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 results:\n",
      "Accuracy: 0.9528\n",
      "Best accuracy so far: 0.9583\n",
      "Trial duration: 0:00:01.427783\n",
      "Average trial duration: 2.36 seconds\n",
      "Estimated time remaining: 56.75 seconds\n",
      "\n",
      "Trial 27/50 started at 00:48:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:56,325] Trial 26 finished with value: 0.9555555555555556 and parameters: {'depth': 1, 'learning_rate': 0.11771980386435399, 'iterations': 611, 'l2_leaf_reg': 1.0383388011241375, 'border_count': 197}. Best is trial 21 with value: 0.9583333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 results:\n",
      "Accuracy: 0.9556\n",
      "Best accuracy so far: 0.9583\n",
      "Trial duration: 0:00:00.944157\n",
      "Average trial duration: 2.31 seconds\n",
      "Estimated time remaining: 53.17 seconds\n",
      "\n",
      "Trial 28/50 started at 00:48:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:48:56,946] Trial 27 finished with value: 0.9527777777777777 and parameters: {'depth': 1, 'learning_rate': 0.14550930622962918, 'iterations': 350, 'l2_leaf_reg': 0.6002124449481516, 'border_count': 200}. Best is trial 21 with value: 0.9583333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28 results:\n",
      "Accuracy: 0.9528\n",
      "Best accuracy so far: 0.9583\n",
      "Trial duration: 0:00:00.618133\n",
      "Average trial duration: 2.25 seconds\n",
      "Estimated time remaining: 49.53 seconds\n",
      "\n",
      "Trial 29/50 started at 00:48:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:13,649] Trial 28 finished with value: 0.9277777777777778 and parameters: {'depth': 10, 'learning_rate': 0.11854171023542935, 'iterations': 622, 'l2_leaf_reg': 3.632298941646622, 'border_count': 223}. Best is trial 21 with value: 0.9583333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 results:\n",
      "Accuracy: 0.9278\n",
      "Best accuracy so far: 0.9583\n",
      "Trial duration: 0:00:16.701347\n",
      "Average trial duration: 2.75 seconds\n",
      "Estimated time remaining: 57.74 seconds\n",
      "\n",
      "Trial 30/50 started at 00:49:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:14,156] Trial 29 finished with value: 0.95 and parameters: {'depth': 1, 'learning_rate': 0.2955859393114292, 'iterations': 480, 'l2_leaf_reg': 1.041120919956213, 'border_count': 193}. Best is trial 21 with value: 0.9583333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 results:\n",
      "Accuracy: 0.9500\n",
      "Best accuracy so far: 0.9583\n",
      "Trial duration: 0:00:00.504585\n",
      "Average trial duration: 2.67 seconds\n",
      "Estimated time remaining: 53.50 seconds\n",
      "\n",
      "Trial 31/50 started at 00:49:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:24,421] Trial 30 finished with value: 0.9361111111111111 and parameters: {'depth': 8, 'learning_rate': 0.045870476742876816, 'iterations': 739, 'l2_leaf_reg': 7.126825553750653, 'border_count': 175}. Best is trial 21 with value: 0.9583333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31 results:\n",
      "Accuracy: 0.9361\n",
      "Best accuracy so far: 0.9583\n",
      "Trial duration: 0:00:10.262199\n",
      "Average trial duration: 2.92 seconds\n",
      "Estimated time remaining: 55.47 seconds\n",
      "\n",
      "Trial 32/50 started at 00:49:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:26,560] Trial 31 finished with value: 0.9444444444444444 and parameters: {'depth': 2, 'learning_rate': 0.01520197063617371, 'iterations': 573, 'l2_leaf_reg': 0.026309935935335624, 'border_count': 149}. Best is trial 21 with value: 0.9583333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32 results:\n",
      "Accuracy: 0.9444\n",
      "Best accuracy so far: 0.9583\n",
      "Trial duration: 0:00:02.136377\n",
      "Average trial duration: 2.90 seconds\n",
      "Estimated time remaining: 52.11 seconds\n",
      "\n",
      "Trial 33/50 started at 00:49:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:28,898] Trial 32 finished with value: 0.9472222222222222 and parameters: {'depth': 3, 'learning_rate': 0.028669845126456272, 'iterations': 623, 'l2_leaf_reg': 0.3528852106123443, 'border_count': 180}. Best is trial 21 with value: 0.9583333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33 results:\n",
      "Accuracy: 0.9472\n",
      "Best accuracy so far: 0.9583\n",
      "Trial duration: 0:00:02.335922\n",
      "Average trial duration: 2.88 seconds\n",
      "Estimated time remaining: 48.93 seconds\n",
      "\n",
      "Trial 34/50 started at 00:49:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:29,376] Trial 33 finished with value: 0.9611111111111111 and parameters: {'depth': 2, 'learning_rate': 0.2044854959627784, 'iterations': 520, 'l2_leaf_reg': 0.0472394887803851, 'border_count': 168}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34 results:\n",
      "Accuracy: 0.9611\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:00.476694\n",
      "Average trial duration: 2.81 seconds\n",
      "Estimated time remaining: 44.92 seconds\n",
      "\n",
      "Trial 35/50 started at 00:49:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:30,055] Trial 34 finished with value: 0.9583333333333334 and parameters: {'depth': 2, 'learning_rate': 0.09425299894301184, 'iterations': 509, 'l2_leaf_reg': 0.15180235089247743, 'border_count': 206}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 results:\n",
      "Accuracy: 0.9583\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:00.678265\n",
      "Average trial duration: 2.75 seconds\n",
      "Estimated time remaining: 41.20 seconds\n",
      "\n",
      "Trial 36/50 started at 00:49:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:30,588] Trial 35 finished with value: 0.9388888888888889 and parameters: {'depth': 4, 'learning_rate': 0.2047001805054605, 'iterations': 366, 'l2_leaf_reg': 0.005620738640575396, 'border_count': 164}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36 results:\n",
      "Accuracy: 0.9389\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:00.531026\n",
      "Average trial duration: 2.69 seconds\n",
      "Estimated time remaining: 37.59 seconds\n",
      "\n",
      "Trial 37/50 started at 00:49:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:31,502] Trial 36 finished with value: 0.9472222222222222 and parameters: {'depth': 2, 'learning_rate': 0.07875127290285716, 'iterations': 523, 'l2_leaf_reg': 0.11952290023149466, 'border_count': 230}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37 results:\n",
      "Accuracy: 0.9472\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:00.912355\n",
      "Average trial duration: 2.64 seconds\n",
      "Estimated time remaining: 34.28 seconds\n",
      "\n",
      "Trial 38/50 started at 00:49:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:32,708] Trial 37 finished with value: 0.9361111111111111 and parameters: {'depth': 7, 'learning_rate': 0.1852250283726624, 'iterations': 257, 'l2_leaf_reg': 0.0006287018059243696, 'border_count': 207}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38 results:\n",
      "Accuracy: 0.9361\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:01.203007\n",
      "Average trial duration: 2.60 seconds\n",
      "Estimated time remaining: 31.19 seconds\n",
      "\n",
      "Trial 39/50 started at 00:49:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:33,440] Trial 38 finished with value: 0.9472222222222222 and parameters: {'depth': 5, 'learning_rate': 0.10657119677122034, 'iterations': 540, 'l2_leaf_reg': 6.3183927105497e-05, 'border_count': 171}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39 results:\n",
      "Accuracy: 0.9472\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:00.729971\n",
      "Average trial duration: 2.55 seconds\n",
      "Estimated time remaining: 28.07 seconds\n",
      "\n",
      "Trial 40/50 started at 00:49:33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:34,597] Trial 39 finished with value: 0.95 and parameters: {'depth': 2, 'learning_rate': 0.04999736797877369, 'iterations': 468, 'l2_leaf_reg': 0.002981336489233343, 'border_count': 253}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 results:\n",
      "Accuracy: 0.9500\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:01.156163\n",
      "Average trial duration: 2.52 seconds\n",
      "Estimated time remaining: 25.17 seconds\n",
      "\n",
      "Trial 41/50 started at 00:49:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:35,408] Trial 40 finished with value: 0.95 and parameters: {'depth': 3, 'learning_rate': 0.1003010731348784, 'iterations': 291, 'l2_leaf_reg': 0.20523952099134984, 'border_count': 148}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 results:\n",
      "Accuracy: 0.9500\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:00.808060\n",
      "Average trial duration: 2.48 seconds\n",
      "Estimated time remaining: 22.28 seconds\n",
      "\n",
      "Trial 42/50 started at 00:49:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:36,018] Trial 41 finished with value: 0.9555555555555556 and parameters: {'depth': 1, 'learning_rate': 0.1549590623190442, 'iterations': 614, 'l2_leaf_reg': 0.05904640344311738, 'border_count': 188}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42 results:\n",
      "Accuracy: 0.9556\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:00.608137\n",
      "Average trial duration: 2.43 seconds\n",
      "Estimated time remaining: 19.44 seconds\n",
      "\n",
      "Trial 43/50 started at 00:49:36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:36,617] Trial 42 finished with value: 0.9527777777777777 and parameters: {'depth': 1, 'learning_rate': 0.21365590869699538, 'iterations': 667, 'l2_leaf_reg': 1.494553436912864, 'border_count': 203}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43 results:\n",
      "Accuracy: 0.9528\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:00.598219\n",
      "Average trial duration: 2.39 seconds\n",
      "Estimated time remaining: 16.72 seconds\n",
      "\n",
      "Trial 44/50 started at 00:49:36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:37,861] Trial 43 finished with value: 0.9555555555555556 and parameters: {'depth': 1, 'learning_rate': 0.05842328569960909, 'iterations': 583, 'l2_leaf_reg': 0.14033438226605818, 'border_count': 181}. Best is trial 33 with value: 0.9611111111111111.\n",
      "[I 2024-11-04 00:49:37,995] Trial 44 finished with value: 0.8888888888888888 and parameters: {'depth': 2, 'learning_rate': 0.03552703914660787, 'iterations': 15, 'l2_leaf_reg': 0.33400354828789086, 'border_count': 237}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 results:\n",
      "Accuracy: 0.9556\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:01.243257\n",
      "Average trial duration: 2.36 seconds\n",
      "Estimated time remaining: 14.17 seconds\n",
      "\n",
      "Trial 45/50 started at 00:49:37\n",
      "Trial 45 results:\n",
      "Accuracy: 0.8889\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:00.132337\n",
      "Average trial duration: 2.31 seconds\n",
      "Estimated time remaining: 11.56 seconds\n",
      "\n",
      "Trial 46/50 started at 00:49:37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:38,952] Trial 45 finished with value: 0.9611111111111111 and parameters: {'depth': 1, 'learning_rate': 0.09858183364004611, 'iterations': 433, 'l2_leaf_reg': 0.48365792579215994, 'border_count': 192}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 results:\n",
      "Accuracy: 0.9611\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:00.955315\n",
      "Average trial duration: 2.28 seconds\n",
      "Estimated time remaining: 9.13 seconds\n",
      "\n",
      "Trial 47/50 started at 00:49:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:39,753] Trial 46 finished with value: 0.9444444444444444 and parameters: {'depth': 3, 'learning_rate': 0.09376241158956079, 'iterations': 380, 'l2_leaf_reg': 0.012138760883014178, 'border_count': 142}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47 results:\n",
      "Accuracy: 0.9444\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:00.798405\n",
      "Average trial duration: 2.25 seconds\n",
      "Estimated time remaining: 6.75 seconds\n",
      "\n",
      "Trial 48/50 started at 00:49:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:40,579] Trial 47 finished with value: 0.9555555555555556 and parameters: {'depth': 1, 'learning_rate': 0.07203761938474994, 'iterations': 433, 'l2_leaf_reg': 0.026825007553476103, 'border_count': 168}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48 results:\n",
      "Accuracy: 0.9556\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:00.825335\n",
      "Average trial duration: 2.22 seconds\n",
      "Estimated time remaining: 4.44 seconds\n",
      "\n",
      "Trial 49/50 started at 00:49:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:42,530] Trial 48 finished with value: 0.95 and parameters: {'depth': 2, 'learning_rate': 0.022011216982598867, 'iterations': 515, 'l2_leaf_reg': 0.5629918401898496, 'border_count': 123}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49 results:\n",
      "Accuracy: 0.9500\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:01.948191\n",
      "Average trial duration: 2.22 seconds\n",
      "Estimated time remaining: 2.22 seconds\n",
      "\n",
      "Trial 50/50 started at 00:49:42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:49:43,042] Trial 49 finished with value: 0.9472222222222222 and parameters: {'depth': 3, 'learning_rate': 0.14947645887702457, 'iterations': 420, 'l2_leaf_reg': 0.08007217434813806, 'border_count': 186}. Best is trial 33 with value: 0.9611111111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 results:\n",
      "Accuracy: 0.9472\n",
      "Best accuracy so far: 0.9611\n",
      "Trial duration: 0:00:00.510816\n",
      "Average trial duration: 2.18 seconds\n",
      "Estimated time remaining: 0.00 seconds\n",
      "\n",
      "Bayesian Optimization completed at 00:49:43\n",
      "Total duration: 0:01:49.219972\n",
      "\n",
      "Best parameters (Bayesian Optimization): {'depth': 2, 'learning_rate': 0.2044854959627784, 'iterations': 520, 'l2_leaf_reg': 0.0472394887803851, 'border_count': 168}\n",
      "Best accuracy (Bayesian Optimization): 0.9611111111111111\n",
      "\n",
      "Total optimization time: 0:07:43.496803\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def prepare_data(X, y, random_state=42):\n",
    "    print(f\"\\nPreparing data...\")\n",
    "    print(f\"Input shape: X={X.shape}, y={y.shape}\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=360, train_size=840, stratify=y, random_state=random_state)\n",
    "    print(f\"After split: X_train={X_train.shape}, X_test={X_test.shape}\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print(\"Data scaling completed\")\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "# Genetic Algorithm\n",
    "def genetic_algorithm(X, y, random_state=42):\n",
    "    start_time = datetime.now()\n",
    "    print(f\"\\nStarting Genetic Algorithm at {start_time.strftime('%H:%M:%S')}\")\n",
    "    X_train, X_test, y_train, y_test = prepare_data(X, y, random_state)\n",
    "\n",
    "    def evaluate(individual):\n",
    "        params = {\n",
    "            'depth': max(1, individual[0]),\n",
    "            'learning_rate': max(0.001, individual[1]),\n",
    "            'iterations': max(10, individual[2]),  \n",
    "            'l2_leaf_reg': max(0, individual[3]),\n",
    "            'border_count': max(32, individual[4]),\n",
    "            'verbose': False\n",
    "        }\n",
    "        clf = CatBoostClassifier(**params, random_state=random_state)\n",
    "        clf.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=20, verbose=False)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        return acc,\n",
    "\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_depth\", random.randint, 1, 10)\n",
    "    toolbox.register(\"attr_learning_rate\", random.uniform, 0.001, 0.3)\n",
    "    toolbox.register(\"attr_iterations\", random.randint, 10, 1000)\n",
    "    toolbox.register(\"attr_l2_leaf_reg\", random.uniform, 0, 10)\n",
    "    toolbox.register(\"attr_border_count\", random.randint, 32, 255)\n",
    "\n",
    "    toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                     (toolbox.attr_depth, toolbox.attr_learning_rate, toolbox.attr_iterations,\n",
    "                      toolbox.attr_l2_leaf_reg, toolbox.attr_border_count), n=1)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population(n=50)\n",
    "    ngen = 10\n",
    "\n",
    "    # Add statistics for tracking progress\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    stats.register(\"std\", np.std)\n",
    "\n",
    "    print(f\"\\nGA Configuration:\")\n",
    "    print(f\"Population size: {len(population)}\")\n",
    "    print(f\"Number of generations: {ngen}\")\n",
    "    print(f\"Starting evolution...\")\n",
    "\n",
    "    population, logbook = algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, \n",
    "                                            ngen=ngen, stats=stats, verbose=True)\n",
    "\n",
    "    best_individual = tools.selBest(population, k=1)[0]\n",
    "    best_params = {\n",
    "        'depth': max(1, best_individual[0]),\n",
    "        'learning_rate': max(0.001, best_individual[1]),\n",
    "        'iterations': max(10, best_individual[2]),\n",
    "        'l2_leaf_reg': max(0, best_individual[3]),\n",
    "        'border_count': max(32, best_individual[4])\n",
    "    }\n",
    "    best_accuracy = best_individual.fitness.values[0]\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"\\nGA completed at {end_time.strftime('%H:%M:%S')}\")\n",
    "    print(f\"Total duration: {duration}\")\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "# Bayesian Optimization\n",
    "def bayesian_optimization(X, y, random_state=42):\n",
    "    start_time = datetime.now()\n",
    "    print(f\"\\nStarting Bayesian Optimization at {start_time.strftime('%H:%M:%S')}\")\n",
    "    X_train, X_test, y_train, y_test = prepare_data(X, y, random_state)\n",
    "    \n",
    "    best_accuracy_so_far = 0\n",
    "    trial_times = []\n",
    "\n",
    "    def objective(trial):\n",
    "        nonlocal best_accuracy_so_far\n",
    "        trial_start = datetime.now()\n",
    "        print(f\"\\nTrial {trial.number + 1}/50 started at {trial_start.strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        params = {\n",
    "            'depth': trial.suggest_int('depth', 1, 10),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.3),\n",
    "            'iterations': trial.suggest_int('iterations', 10, 1000),\n",
    "            'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.00001, 10),\n",
    "            'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "            'verbose': False\n",
    "        }\n",
    "        clf = CatBoostClassifier(**params, random_state=random_state)\n",
    "        clf.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=20, verbose=False)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        trial_end = datetime.now()\n",
    "        trial_duration = trial_end - trial_start\n",
    "        trial_times.append(trial_duration.total_seconds())\n",
    "        avg_trial_time = np.mean(trial_times)\n",
    "        \n",
    "        best_accuracy_so_far = max(best_accuracy_so_far, accuracy)\n",
    "        print(f\"Trial {trial.number + 1} results:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Best accuracy so far: {best_accuracy_so_far:.4f}\")\n",
    "        print(f\"Trial duration: {trial_duration}\")\n",
    "        print(f\"Average trial duration: {avg_trial_time:.2f} seconds\")\n",
    "        print(f\"Estimated time remaining: {avg_trial_time * (49 - trial.number):.2f} seconds\")\n",
    "        \n",
    "        return accuracy\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    print(f\"Running Bayesian Optimization for 50 trials...\")\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"\\nBayesian Optimization completed at {end_time.strftime('%H:%M:%S')}\")\n",
    "    print(f\"Total duration: {duration}\")\n",
    "    return study.best_params, study.best_value\n",
    "\n",
    "# Main execution\n",
    "random_state = 42\n",
    "\n",
    "print(f\"Starting hyperparameter optimization at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"Number of training samples: 840\")\n",
    "print(f\"Number of testing samples: 360\")\n",
    "print(f\"Total samples: 1200\")\n",
    "\n",
    "print(\"\\nGenetic Algorithm Optimization\")\n",
    "ga_start = datetime.now()\n",
    "ga_best_params, ga_best_accuracy = genetic_algorithm(X, y, random_state=random_state)\n",
    "print(\"\\nBest parameters (Genetic Algorithm):\", ga_best_params)\n",
    "print(\"Best accuracy (Genetic Algorithm):\", ga_best_accuracy)\n",
    "\n",
    "print(\"\\nBayesian Optimization\")\n",
    "bo_start = datetime.now()\n",
    "bo_best_params, bo_best_accuracy = bayesian_optimization(X, y, random_state=random_state)\n",
    "print(\"\\nBest parameters (Bayesian Optimization):\", bo_best_params)\n",
    "print(\"Best accuracy (Bayesian Optimization):\", bo_best_accuracy)\n",
    "\n",
    "total_duration = datetime.now() - ga_start\n",
    "print(f\"\\nTotal optimization time: {total_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ea45a4c-a242-445c-b4e3-e6c25066a6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating XGBOOST\n",
      "Genetic Algorithm Optimization\n",
      "Starting Genetic Algorithm optimization for XGBOOST...\n",
      "gen\tnevals\n",
      "0  \t50    \n",
      "1  \t29    \n",
      "2  \t36    \n",
      "3  \t23    \n",
      "4  \t35    \n",
      "5  \t29    \n",
      "6  \t29    \n",
      "7  \t35    \n",
      "8  \t36    \n",
      "9  \t32    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:53:14,927] A new study created in memory with name: no-name-4423fa4f-adae-4149-9da3-2a2e3913fbcb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \t31    \n",
      "Finished Genetic Algorithm tuning. Time taken: 211.80 seconds\n",
      "\n",
      "Best parameters for XGBOOST (Genetic Algorithm):\n",
      "max_depth: 2\n",
      "learning_rate: 0.2\n",
      "n_estimators: 500\n",
      "subsample: 0.8\n",
      "colsample_bytree: 0.7\n",
      "Best accuracy: 0.9611\n",
      "\n",
      "Bayesian Optimization\n",
      "Starting Bayesian Optimization for XGBOOST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 00:53:15,868] Trial 0 finished with value: 0.95 and parameters: {'max_depth': 7, 'learning_rate': 0.03354925118829631, 'n_estimators': 521, 'subsample': 0.7593081143240401, 'colsample_bytree': 0.6350385864774327}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:16,960] Trial 1 finished with value: 0.9388888888888889 and parameters: {'max_depth': 8, 'learning_rate': 0.010908491107232394, 'n_estimators': 289, 'subsample': 0.7655945181856924, 'colsample_bytree': 0.8239364080913907}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:17,779] Trial 2 finished with value: 0.9472222222222222 and parameters: {'max_depth': 5, 'learning_rate': 0.020807164454014725, 'n_estimators': 203, 'subsample': 0.6339728494752142, 'colsample_bytree': 0.8053107782145753}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:18,309] Trial 3 finished with value: 0.95 and parameters: {'max_depth': 7, 'learning_rate': 0.24646854578377822, 'n_estimators': 503, 'subsample': 0.6891052540846079, 'colsample_bytree': 0.9853809509547893}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:18,863] Trial 4 finished with value: 0.9444444444444444 and parameters: {'max_depth': 8, 'learning_rate': 0.18515574300886317, 'n_estimators': 84, 'subsample': 0.8076181882195096, 'colsample_bytree': 0.6746914621529213}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:19,874] Trial 5 finished with value: 0.95 and parameters: {'max_depth': 6, 'learning_rate': 0.02722687373922676, 'n_estimators': 336, 'subsample': 0.6012102046604234, 'colsample_bytree': 0.6558371136095743}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:20,759] Trial 6 finished with value: 0.9416666666666667 and parameters: {'max_depth': 5, 'learning_rate': 0.014160025058977099, 'n_estimators': 250, 'subsample': 0.6909080668624991, 'colsample_bytree': 0.6785555696807375}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:21,950] Trial 7 finished with value: 0.9361111111111111 and parameters: {'max_depth': 8, 'learning_rate': 0.015799982538534853, 'n_estimators': 358, 'subsample': 0.9761091160715427, 'colsample_bytree': 0.8756914629405874}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:22,675] Trial 8 finished with value: 0.9361111111111111 and parameters: {'max_depth': 10, 'learning_rate': 0.014876039828392919, 'n_estimators': 116, 'subsample': 0.7220745802850378, 'colsample_bytree': 0.6426416343462965}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:23,283] Trial 9 finished with value: 0.9444444444444444 and parameters: {'max_depth': 8, 'learning_rate': 0.08676582974749143, 'n_estimators': 193, 'subsample': 0.7108919509939726, 'colsample_bytree': 0.7591039415997164}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:23,938] Trial 10 finished with value: 0.9472222222222222 and parameters: {'max_depth': 3, 'learning_rate': 0.0470924714184662, 'n_estimators': 524, 'subsample': 0.8609398440089244, 'colsample_bytree': 0.608422171509036}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:24,514] Trial 11 finished with value: 0.95 and parameters: {'max_depth': 6, 'learning_rate': 0.22294309297690337, 'n_estimators': 519, 'subsample': 0.8706600347830991, 'colsample_bytree': 0.9696105308051189}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:25,124] Trial 12 finished with value: 0.9472222222222222 and parameters: {'max_depth': 10, 'learning_rate': 0.09293622080060393, 'n_estimators': 427, 'subsample': 0.6684356111159377, 'colsample_bytree': 0.9741660486798949}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:25,988] Trial 13 finished with value: 0.9472222222222222 and parameters: {'max_depth': 7, 'learning_rate': 0.043121723400535314, 'n_estimators': 442, 'subsample': 0.7895536624392315, 'colsample_bytree': 0.7414904532752882}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:26,538] Trial 14 finished with value: 0.9388888888888889 and parameters: {'max_depth': 4, 'learning_rate': 0.11352348731737381, 'n_estimators': 452, 'subsample': 0.7512779872989283, 'colsample_bytree': 0.9058658792077376}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:27,494] Trial 15 finished with value: 0.9444444444444444 and parameters: {'max_depth': 7, 'learning_rate': 0.02990273658013254, 'n_estimators': 547, 'subsample': 0.8932984044082096, 'colsample_bytree': 0.9132719879005884}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:28,063] Trial 16 finished with value: 0.9416666666666667 and parameters: {'max_depth': 9, 'learning_rate': 0.14479636031864024, 'n_estimators': 384, 'subsample': 0.8273248103499515, 'colsample_bytree': 0.7249534050355512}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:28,595] Trial 17 finished with value: 0.9416666666666667 and parameters: {'max_depth': 5, 'learning_rate': 0.27532445313355086, 'n_estimators': 480, 'subsample': 0.6556422686296448, 'colsample_bytree': 0.8468586478023531}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:29,320] Trial 18 finished with value: 0.9444444444444444 and parameters: {'max_depth': 7, 'learning_rate': 0.06319052175298825, 'n_estimators': 488, 'subsample': 0.9256703734169061, 'colsample_bytree': 0.7682534052467037}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:30,080] Trial 19 finished with value: 0.9416666666666667 and parameters: {'max_depth': 9, 'learning_rate': 0.05759690041980194, 'n_estimators': 398, 'subsample': 0.7406927265344432, 'colsample_bytree': 0.9987592307317141}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:31,007] Trial 20 finished with value: 0.95 and parameters: {'max_depth': 6, 'learning_rate': 0.032141548882928826, 'n_estimators': 550, 'subsample': 0.6061837807781574, 'colsample_bytree': 0.7098490085013451}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:32,017] Trial 21 finished with value: 0.9444444444444444 and parameters: {'max_depth': 6, 'learning_rate': 0.027805932615421147, 'n_estimators': 329, 'subsample': 0.616250747540481, 'colsample_bytree': 0.6201681968613373}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:33,140] Trial 22 finished with value: 0.9472222222222222 and parameters: {'max_depth': 7, 'learning_rate': 0.021481935835417576, 'n_estimators': 487, 'subsample': 0.6660114163786126, 'colsample_bytree': 0.6562160934890335}. Best is trial 0 with value: 0.95.\n",
      "[I 2024-11-04 00:53:34,027] Trial 23 finished with value: 0.9527777777777777 and parameters: {'max_depth': 6, 'learning_rate': 0.03758882599317193, 'n_estimators': 287, 'subsample': 0.6926137439560578, 'colsample_bytree': 0.6892905257497403}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:34,770] Trial 24 finished with value: 0.9444444444444444 and parameters: {'max_depth': 4, 'learning_rate': 0.03810446339874673, 'n_estimators': 293, 'subsample': 0.7004387104833981, 'colsample_bytree': 0.6950889961663131}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:35,437] Trial 25 finished with value: 0.9444444444444444 and parameters: {'max_depth': 9, 'learning_rate': 0.07039806665018918, 'n_estimators': 188, 'subsample': 0.7830227669709038, 'colsample_bytree': 0.7725199716085066}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:36,060] Trial 26 finished with value: 0.9416666666666667 and parameters: {'max_depth': 7, 'learning_rate': 0.13381198128207278, 'n_estimators': 412, 'subsample': 0.729843797214788, 'colsample_bytree': 0.6027743245231635}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:36,990] Trial 27 finished with value: 0.9444444444444444 and parameters: {'max_depth': 5, 'learning_rate': 0.02181579269600298, 'n_estimators': 263, 'subsample': 0.6873681027153804, 'colsample_bytree': 0.9265035621940167}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:37,715] Trial 28 finished with value: 0.9388888888888889 and parameters: {'max_depth': 6, 'learning_rate': 0.051875682332928746, 'n_estimators': 240, 'subsample': 0.8211758304500424, 'colsample_bytree': 0.6411338532124088}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:38,528] Trial 29 finished with value: 0.9333333333333333 and parameters: {'max_depth': 8, 'learning_rate': 0.010882885630791626, 'n_estimators': 147, 'subsample': 0.7734367817490405, 'colsample_bytree': 0.8043230985646025}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:39,342] Trial 30 finished with value: 0.9472222222222222 and parameters: {'max_depth': 7, 'learning_rate': 0.03792984212102282, 'n_estimators': 317, 'subsample': 0.7499646590809838, 'colsample_bytree': 0.829081432388354}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:40,368] Trial 31 finished with value: 0.95 and parameters: {'max_depth': 6, 'learning_rate': 0.02477925818033047, 'n_estimators': 355, 'subsample': 0.6515403612500519, 'colsample_bytree': 0.6790149027956539}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:41,238] Trial 32 finished with value: 0.95 and parameters: {'max_depth': 5, 'learning_rate': 0.034585912759429106, 'n_estimators': 361, 'subsample': 0.6371334033445137, 'colsample_bytree': 0.6348848586518842}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:42,557] Trial 33 finished with value: 0.9472222222222222 and parameters: {'max_depth': 6, 'learning_rate': 0.018218108434242843, 'n_estimators': 470, 'subsample': 0.6215594155694973, 'colsample_bytree': 0.6626352674259359}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:43,202] Trial 34 finished with value: 0.95 and parameters: {'max_depth': 4, 'learning_rate': 0.07739006408472929, 'n_estimators': 227, 'subsample': 0.6817954782976668, 'colsample_bytree': 0.6964217087044206}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:44,187] Trial 35 finished with value: 0.95 and parameters: {'max_depth': 8, 'learning_rate': 0.024679999128446747, 'n_estimators': 288, 'subsample': 0.6371058821551964, 'colsample_bytree': 0.7297856704923782}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:44,941] Trial 36 finished with value: 0.9416666666666667 and parameters: {'max_depth': 6, 'learning_rate': 0.04065592024144532, 'n_estimators': 514, 'subsample': 0.6973769344328128, 'colsample_bytree': 0.8748564737797382}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:45,968] Trial 37 finished with value: 0.9361111111111111 and parameters: {'max_depth': 7, 'learning_rate': 0.013203277507905637, 'n_estimators': 271, 'subsample': 0.6007103560124434, 'colsample_bytree': 0.6710401513368105}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:46,709] Trial 38 finished with value: 0.9305555555555556 and parameters: {'max_depth': 5, 'learning_rate': 0.01790710883960616, 'n_estimators': 162, 'subsample': 0.7194890793584561, 'colsample_bytree': 0.6278316004950237}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:47,437] Trial 39 finished with value: 0.9444444444444444 and parameters: {'max_depth': 8, 'learning_rate': 0.050416979458671116, 'n_estimators': 324, 'subsample': 0.7597372276146047, 'colsample_bytree': 0.7927717729757701}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:47,975] Trial 40 finished with value: 0.9472222222222222 and parameters: {'max_depth': 6, 'learning_rate': 0.18795440343165, 'n_estimators': 370, 'subsample': 0.9995825050896304, 'colsample_bytree': 0.6890931445878196}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:48,508] Trial 41 finished with value: 0.9444444444444444 and parameters: {'max_depth': 6, 'learning_rate': 0.28368926684352613, 'n_estimators': 508, 'subsample': 0.8614541458355016, 'colsample_bytree': 0.9577751938150723}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:49,081] Trial 42 finished with value: 0.9416666666666667 and parameters: {'max_depth': 7, 'learning_rate': 0.1955533434974613, 'n_estimators': 77, 'subsample': 0.9322292906953695, 'colsample_bytree': 0.9667776112050991}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:49,648] Trial 43 finished with value: 0.9472222222222222 and parameters: {'max_depth': 6, 'learning_rate': 0.23508585140992427, 'n_estimators': 456, 'subsample': 0.8035464085948324, 'colsample_bytree': 0.9418857003342597}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:50,229] Trial 44 finished with value: 0.9444444444444444 and parameters: {'max_depth': 5, 'learning_rate': 0.15218504358840343, 'n_estimators': 522, 'subsample': 0.8726835786114822, 'colsample_bytree': 0.9922034837909727}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:50,989] Trial 45 finished with value: 0.9527777777777777 and parameters: {'max_depth': 8, 'learning_rate': 0.10355384502341941, 'n_estimators': 432, 'subsample': 0.839103855894868, 'colsample_bytree': 0.9846952884153902}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:51,626] Trial 46 finished with value: 0.9444444444444444 and parameters: {'max_depth': 9, 'learning_rate': 0.09247866697986211, 'n_estimators': 431, 'subsample': 0.8259633339654057, 'colsample_bytree': 0.8853623459224529}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:52,219] Trial 47 finished with value: 0.9416666666666667 and parameters: {'max_depth': 8, 'learning_rate': 0.1089139913499591, 'n_estimators': 53, 'subsample': 0.8488881317323135, 'colsample_bytree': 0.6496378228321145}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:53,043] Trial 48 finished with value: 0.9444444444444444 and parameters: {'max_depth': 8, 'learning_rate': 0.04396406245455691, 'n_estimators': 498, 'subsample': 0.7333584956790381, 'colsample_bytree': 0.9407227942249566}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:54,088] Trial 49 finished with value: 0.9416666666666667 and parameters: {'max_depth': 7, 'learning_rate': 0.02705307946423659, 'n_estimators': 466, 'subsample': 0.7106274973224802, 'colsample_bytree': 0.6157725729586376}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:54,935] Trial 50 finished with value: 0.9472222222222222 and parameters: {'max_depth': 7, 'learning_rate': 0.033612007909118204, 'n_estimators': 534, 'subsample': 0.7884412334150053, 'colsample_bytree': 0.9820153544062173}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:55,468] Trial 51 finished with value: 0.9472222222222222 and parameters: {'max_depth': 7, 'learning_rate': 0.23351472473388366, 'n_estimators': 411, 'subsample': 0.9117731861714168, 'colsample_bytree': 0.95059955948755}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:56,028] Trial 52 finished with value: 0.9333333333333333 and parameters: {'max_depth': 8, 'learning_rate': 0.22072214776709173, 'n_estimators': 540, 'subsample': 0.8824992957777997, 'colsample_bytree': 0.9776170308266894}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:56,586] Trial 53 finished with value: 0.9416666666666667 and parameters: {'max_depth': 6, 'learning_rate': 0.17343160506429198, 'n_estimators': 443, 'subsample': 0.8978538798787838, 'colsample_bytree': 0.9122814571856781}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:57,257] Trial 54 finished with value: 0.9388888888888889 and parameters: {'max_depth': 7, 'learning_rate': 0.11558826921595598, 'n_estimators': 498, 'subsample': 0.8529494990673513, 'colsample_bytree': 0.7134276747499863}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:57,792] Trial 55 finished with value: 0.9416666666666667 and parameters: {'max_depth': 6, 'learning_rate': 0.25844187086168136, 'n_estimators': 482, 'subsample': 0.8124535671331196, 'colsample_bytree': 0.998517701030035}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:58,462] Trial 56 finished with value: 0.9472222222222222 and parameters: {'max_depth': 5, 'learning_rate': 0.06265973152985312, 'n_estimators': 385, 'subsample': 0.8343756563955059, 'colsample_bytree': 0.9669088291625145}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:59,045] Trial 57 finished with value: 0.9388888888888889 and parameters: {'max_depth': 9, 'learning_rate': 0.16216255755307202, 'n_estimators': 343, 'subsample': 0.6742947788204048, 'colsample_bytree': 0.7498517454113859}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:53:59,571] Trial 58 finished with value: 0.9444444444444444 and parameters: {'max_depth': 8, 'learning_rate': 0.20109980575171932, 'n_estimators': 529, 'subsample': 0.6585207115035276, 'colsample_bytree': 0.9252838549973655}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:00,364] Trial 59 finished with value: 0.9388888888888889 and parameters: {'max_depth': 4, 'learning_rate': 0.02859982938767606, 'n_estimators': 218, 'subsample': 0.9571084311605648, 'colsample_bytree': 0.8561794499450188}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:00,959] Trial 60 finished with value: 0.9472222222222222 and parameters: {'max_depth': 7, 'learning_rate': 0.12623401493435515, 'n_estimators': 435, 'subsample': 0.7469313867053705, 'colsample_bytree': 0.7811195727343502}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:01,860] Trial 61 finished with value: 0.9472222222222222 and parameters: {'max_depth': 6, 'learning_rate': 0.03353084846842582, 'n_estimators': 549, 'subsample': 0.6458682271109447, 'colsample_bytree': 0.7174185856053914}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:02,777] Trial 62 finished with value: 0.9472222222222222 and parameters: {'max_depth': 6, 'learning_rate': 0.031122187729727538, 'n_estimators': 506, 'subsample': 0.6180961388248872, 'colsample_bytree': 0.6634827409847972}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:03,664] Trial 63 finished with value: 0.9527777777777777 and parameters: {'max_depth': 5, 'learning_rate': 0.023330193341774066, 'n_estimators': 524, 'subsample': 0.6027886458534073, 'colsample_bytree': 0.6487671109239266}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:04,651] Trial 64 finished with value: 0.95 and parameters: {'max_depth': 5, 'learning_rate': 0.023545165871963973, 'n_estimators': 309, 'subsample': 0.7715859997066554, 'colsample_bytree': 0.6474798141076171}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:05,694] Trial 65 finished with value: 0.9388888888888889 and parameters: {'max_depth': 5, 'learning_rate': 0.016414624100041433, 'n_estimators': 465, 'subsample': 0.8420745253860292, 'colsample_bytree': 0.6096466497202564}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:06,698] Trial 66 finished with value: 0.95 and parameters: {'max_depth': 3, 'learning_rate': 0.01960525815620511, 'n_estimators': 521, 'subsample': 0.6213574516188708, 'colsample_bytree': 0.625996416582926}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:07,562] Trial 67 finished with value: 0.9472222222222222 and parameters: {'max_depth': 5, 'learning_rate': 0.03800777458350266, 'n_estimators': 488, 'subsample': 0.6098161709698777, 'colsample_bytree': 0.6807117337410845}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:08,613] Trial 68 finished with value: 0.9472222222222222 and parameters: {'max_depth': 7, 'learning_rate': 0.026670777654894357, 'n_estimators': 420, 'subsample': 0.6296831391947992, 'colsample_bytree': 0.63602784757503}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:09,607] Trial 69 finished with value: 0.9388888888888889 and parameters: {'max_depth': 6, 'learning_rate': 0.013567657235875406, 'n_estimators': 256, 'subsample': 0.6727736895703562, 'colsample_bytree': 0.9869448861127774}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:10,161] Trial 70 finished with value: 0.9472222222222222 and parameters: {'max_depth': 10, 'learning_rate': 0.2942373961303381, 'n_estimators': 274, 'subsample': 0.794617611119541, 'colsample_bytree': 0.6600241746493366}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:10,938] Trial 71 finished with value: 0.95 and parameters: {'max_depth': 6, 'learning_rate': 0.04641091206592414, 'n_estimators': 547, 'subsample': 0.6010608770093587, 'colsample_bytree': 0.706787410966251}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:11,841] Trial 72 finished with value: 0.9472222222222222 and parameters: {'max_depth': 6, 'learning_rate': 0.031450781108977297, 'n_estimators': 531, 'subsample': 0.6463454959200564, 'colsample_bytree': 0.7353628153987066}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:12,934] Trial 73 finished with value: 0.95 and parameters: {'max_depth': 5, 'learning_rate': 0.0213209506008765, 'n_estimators': 513, 'subsample': 0.6302606712192012, 'colsample_bytree': 0.6714087619162905}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:13,800] Trial 74 finished with value: 0.95 and parameters: {'max_depth': 7, 'learning_rate': 0.05802073310714361, 'n_estimators': 476, 'subsample': 0.6077508070945792, 'colsample_bytree': 0.6011715479699763}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:14,790] Trial 75 finished with value: 0.9444444444444444 and parameters: {'max_depth': 6, 'learning_rate': 0.035782905053786826, 'n_estimators': 494, 'subsample': 0.7013708531049656, 'colsample_bytree': 0.8204072818005507}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:15,678] Trial 76 finished with value: 0.9472222222222222 and parameters: {'max_depth': 5, 'learning_rate': 0.04116875974953525, 'n_estimators': 338, 'subsample': 0.6625523009122809, 'colsample_bytree': 0.6958914789709163}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:16,306] Trial 77 finished with value: 0.9527777777777777 and parameters: {'max_depth': 4, 'learning_rate': 0.08094905953004639, 'n_estimators': 517, 'subsample': 0.6875806714248176, 'colsample_bytree': 0.6475216348520958}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:16,935] Trial 78 finished with value: 0.9472222222222222 and parameters: {'max_depth': 4, 'learning_rate': 0.07950368844174345, 'n_estimators': 451, 'subsample': 0.7173257191307214, 'colsample_bytree': 0.6510671775250411}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:17,599] Trial 79 finished with value: 0.9444444444444444 and parameters: {'max_depth': 3, 'learning_rate': 0.07381408751667082, 'n_estimators': 299, 'subsample': 0.6856675034282239, 'colsample_bytree': 0.6278038695643828}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:18,697] Trial 80 finished with value: 0.9444444444444444 and parameters: {'max_depth': 7, 'learning_rate': 0.023571202704162207, 'n_estimators': 513, 'subsample': 0.7044411056490555, 'colsample_bytree': 0.6412527751029861}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:19,350] Trial 81 finished with value: 0.95 and parameters: {'max_depth': 4, 'learning_rate': 0.05072900315714238, 'n_estimators': 535, 'subsample': 0.6400557486648462, 'colsample_bytree': 0.6855823377539462}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:19,972] Trial 82 finished with value: 0.9444444444444444 and parameters: {'max_depth': 4, 'learning_rate': 0.09091391667134224, 'n_estimators': 500, 'subsample': 0.8720678655267158, 'colsample_bytree': 0.6670929888236963}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:21,013] Trial 83 finished with value: 0.95 and parameters: {'max_depth': 6, 'learning_rate': 0.02566853045989896, 'n_estimators': 550, 'subsample': 0.7356798169451547, 'colsample_bytree': 0.6565397204011534}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:21,713] Trial 84 finished with value: 0.95 and parameters: {'max_depth': 8, 'learning_rate': 0.09875098782092731, 'n_estimators': 523, 'subsample': 0.8163258637187278, 'colsample_bytree': 0.7035255332583947}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:22,677] Trial 85 finished with value: 0.9444444444444444 and parameters: {'max_depth': 6, 'learning_rate': 0.03059548961705572, 'n_estimators': 282, 'subsample': 0.6943459288877806, 'colsample_bytree': 0.6172648805210496}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:23,211] Trial 86 finished with value: 0.95 and parameters: {'max_depth': 5, 'learning_rate': 0.25725106972066314, 'n_estimators': 479, 'subsample': 0.611153215276959, 'colsample_bytree': 0.9674687296166227}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:23,892] Trial 87 finished with value: 0.9444444444444444 and parameters: {'max_depth': 9, 'learning_rate': 0.06854517975251594, 'n_estimators': 458, 'subsample': 0.6796690244233213, 'colsample_bytree': 0.9501719724658378}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:24,552] Trial 88 finished with value: 0.9527777777777777 and parameters: {'max_depth': 3, 'learning_rate': 0.05584458024822393, 'n_estimators': 538, 'subsample': 0.7652690214966157, 'colsample_bytree': 0.633492698458363}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:25,149] Trial 89 finished with value: 0.9472222222222222 and parameters: {'max_depth': 3, 'learning_rate': 0.0840291570359481, 'n_estimators': 523, 'subsample': 0.7659931925784805, 'colsample_bytree': 0.6423975632815426}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:25,805] Trial 90 finished with value: 0.9444444444444444 and parameters: {'max_depth': 4, 'learning_rate': 0.05512484447161411, 'n_estimators': 506, 'subsample': 0.7450475170914753, 'colsample_bytree': 0.6307780815367926}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:26,363] Trial 91 finished with value: 0.9472222222222222 and parameters: {'max_depth': 3, 'learning_rate': 0.10197355325268134, 'n_estimators': 536, 'subsample': 0.7567961245249513, 'colsample_bytree': 0.6786466818781229}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:27,169] Trial 92 finished with value: 0.9472222222222222 and parameters: {'max_depth': 6, 'learning_rate': 0.04666630196852838, 'n_estimators': 540, 'subsample': 0.7788037674263042, 'colsample_bytree': 0.6516040951521566}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:27,798] Trial 93 finished with value: 0.95 and parameters: {'max_depth': 3, 'learning_rate': 0.0627519809539421, 'n_estimators': 241, 'subsample': 0.6261219967030639, 'colsample_bytree': 0.612185037742606}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:28,627] Trial 94 finished with value: 0.9444444444444444 and parameters: {'max_depth': 7, 'learning_rate': 0.04228521806079336, 'n_estimators': 491, 'subsample': 0.7990359323014284, 'colsample_bytree': 0.9905248999332573}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:29,238] Trial 95 finished with value: 0.9444444444444444 and parameters: {'max_depth': 6, 'learning_rate': 0.13485793360664672, 'n_estimators': 516, 'subsample': 0.7241635767481516, 'colsample_bytree': 0.6204074089150422}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:30,041] Trial 96 finished with value: 0.9416666666666667 and parameters: {'max_depth': 4, 'learning_rate': 0.028902925805740023, 'n_estimators': 502, 'subsample': 0.8628302295385327, 'colsample_bytree': 0.6710997558729466}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:30,597] Trial 97 finished with value: 0.9527777777777777 and parameters: {'max_depth': 7, 'learning_rate': 0.21232752086706583, 'n_estimators': 403, 'subsample': 0.6548999841561748, 'colsample_bytree': 0.9765662226056189}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:31,177] Trial 98 finished with value: 0.95 and parameters: {'max_depth': 7, 'learning_rate': 0.21738736503040773, 'n_estimators': 380, 'subsample': 0.6655770472395994, 'colsample_bytree': 0.9754126688010047}. Best is trial 23 with value: 0.9527777777777777.\n",
      "[I 2024-11-04 00:54:31,730] Trial 99 finished with value: 0.9444444444444444 and parameters: {'max_depth': 8, 'learning_rate': 0.21550907167770475, 'n_estimators': 354, 'subsample': 0.7099694712864145, 'colsample_bytree': 0.9994054867833247}. Best is trial 23 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Bayesian Optimization tuning. Time taken: 76.81 seconds\n",
      "\n",
      "Best parameters for XGBOOST (Bayesian Optimization):\n",
      "max_depth: 6\n",
      "learning_rate: 0.03758882599317193\n",
      "n_estimators: 287\n",
      "subsample: 0.6926137439560578\n",
      "colsample_bytree: 0.6892905257497403\n",
      "Best accuracy: 0.9528\n",
      "\n",
      "Number of training samples: 840\n",
      "Number of testing samples: 360\n",
      "Total samples: 1200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from deap import base, creator, tools, algorithms\n",
    "import optuna\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the parameter spaces for XGBoost and CatBoost\n",
    "param_space = {\n",
    "    'xgboost': {\n",
    "        'max_depth': list(range(3, 11)),\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "        'n_estimators': list(range(50, 551, 50)),\n",
    "        'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    },\n",
    "    'catboost': {\n",
    "        'depth': list(range(4, 11)),\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "        'iterations': list(range(50, 551, 50)),\n",
    "        'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "        'border_count': [32, 64, 128, 254]\n",
    "    }\n",
    "}\n",
    "\n",
    "def prepare_data(X, y, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=360, train_size=840, stratify=y, random_state=random_state)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "def genetic_algorithm(X, y, classifier_type, random_state=42):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = prepare_data(X, y, random_state)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def evaluate(individual):\n",
    "        if classifier_type == 'xgboost':\n",
    "            clf = XGBClassifier(\n",
    "                max_depth=individual[0],\n",
    "                learning_rate=individual[1],\n",
    "                n_estimators=individual[2],\n",
    "                subsample=min(max(individual[3], 0.6), 1.0),  # Ensure subsample is between 0.6 and 1.0\n",
    "                colsample_bytree=min(max(individual[4], 0.6), 1.0),  # Ensure colsample_bytree is between 0.6 and 1.0\n",
    "                tree_method='gpu_hist' if device == 'cuda' else 'hist',\n",
    "                random_state=random_state,\n",
    "                early_stopping_rounds=10,\n",
    "                eval_metric='logloss'\n",
    "            )\n",
    "            clf.fit(X_train_scaled, y_train, eval_set=[(X_test_scaled, y_test)], verbose=False)\n",
    "        else:  # CatBoost\n",
    "            clf = CatBoostClassifier(\n",
    "                depth=individual[0],\n",
    "                learning_rate=individual[1],\n",
    "                iterations=individual[2],\n",
    "                l2_leaf_reg=individual[3],\n",
    "                border_count=individual[4],\n",
    "                task_type='GPU' if device == 'cuda' else 'CPU',\n",
    "                random_state=random_state,\n",
    "                verbose=False\n",
    "            )\n",
    "            clf.fit(X_train_scaled, y_train, eval_set=(X_test_scaled, y_test), \n",
    "                    early_stopping_rounds=10, verbose=False)\n",
    "        \n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "        return accuracy_score(y_test, y_pred),\n",
    "\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    param_keys = list(param_space[classifier_type].keys())\n",
    "    for i, key in enumerate(param_keys):\n",
    "        toolbox.register(f\"attr_{i}\", random.choice, param_space[classifier_type][key])\n",
    "\n",
    "    toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                     [getattr(toolbox, f\"attr_{i}\") for i in range(len(param_keys))], n=1)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=10, indpb=0.2)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population(n=50)\n",
    "    ngen = 10\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f\"Starting Genetic Algorithm optimization for {classifier_type.upper()}...\")\n",
    "\n",
    "    result, log = algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=ngen, verbose=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Finished Genetic Algorithm tuning. Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    best_individual = tools.selBest(result, k=1)[0]\n",
    "    best_params = dict(zip(param_keys, best_individual))\n",
    "    if classifier_type == 'xgboost':\n",
    "        best_params['subsample'] = min(max(best_params['subsample'], 0.6), 1.0)\n",
    "        best_params['colsample_bytree'] = min(max(best_params['colsample_bytree'], 0.6), 1.0)\n",
    "    best_accuracy = best_individual.fitness.values[0]\n",
    "\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "def bayesian_optimization(X, y, classifier_type, random_state=42):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = prepare_data(X, y, random_state)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def objective(trial):\n",
    "        if classifier_type == 'xgboost':\n",
    "            params = {\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 550),\n",
    "                'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "                'tree_method': 'gpu_hist' if device == 'cuda' else 'hist',\n",
    "                'random_state': random_state,\n",
    "                'early_stopping_rounds': 10,\n",
    "                'eval_metric': 'logloss'\n",
    "            }\n",
    "            clf = XGBClassifier(**params)\n",
    "            clf.fit(X_train_scaled, y_train, eval_set=[(X_test_scaled, y_test)], verbose=False)\n",
    "        else:  # CatBoost\n",
    "            params = {\n",
    "                'depth': trial.suggest_int('depth', 4, 10),\n",
    "                'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "                'iterations': trial.suggest_int('iterations', 50, 550),\n",
    "                'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 9),\n",
    "                'border_count': trial.suggest_categorical('border_count', [32, 64, 128, 254]),\n",
    "                'task_type': 'GPU' if device == 'cuda' else 'CPU',\n",
    "                'random_state': random_state,\n",
    "                'verbose': False\n",
    "            }\n",
    "            clf = CatBoostClassifier(**params)\n",
    "            clf.fit(X_train_scaled, y_train, eval_set=(X_test_scaled, y_test), \n",
    "                    early_stopping_rounds=10, verbose=False)\n",
    "        \n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f\"Starting Bayesian Optimization for {classifier_type.upper()}...\")\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Finished Bayesian Optimization tuning. Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_accuracy = study.best_value\n",
    "\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "# Main execution\n",
    "random_state = 42\n",
    "\n",
    "# Assuming X and y are your feature matrix and target vector\n",
    "# X = ...\n",
    "# y = ...\n",
    "\n",
    "for classifier_type in ['xgboost']:\n",
    "    print(f\"\\nEvaluating {classifier_type.upper()}\")\n",
    "    \n",
    "    print(\"Genetic Algorithm Optimization\")\n",
    "    ga_best_params, ga_best_accuracy = genetic_algorithm(X, y, classifier_type, random_state=random_state)\n",
    "    print(f\"\\nBest parameters for {classifier_type.upper()} (Genetic Algorithm):\")\n",
    "    for param, value in ga_best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    print(f\"Best accuracy: {ga_best_accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\nBayesian Optimization\")\n",
    "    bo_best_params, bo_best_accuracy = bayesian_optimization(X, y, classifier_type, random_state=random_state)\n",
    "    print(f\"\\nBest parameters for {classifier_type.upper()} (Bayesian Optimization):\")\n",
    "    for param, value in bo_best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    print(f\"Best accuracy: {bo_best_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nNumber of training samples: 840\")\n",
    "print(f\"Number of testing samples: 360\")\n",
    "print(f\"Total samples: 1200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93f66ee2-a3f9-4b8b-8897-756755bdf875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest with Genetic Algorithm Optimization\n",
      "Starting Genetic Algorithm optimization for Random Forest...\n",
      "gen\tnevals\n",
      "0  \t50    \n",
      "1  \t35    \n",
      "2  \t35    \n",
      "3  \t26    \n",
      "4  \t32    \n",
      "5  \t34    \n",
      "6  \t25    \n",
      "7  \t26    \n",
      "Error during evaluation: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "8  \t36    \n",
      "9  \t29    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 01:01:02,311] A new study created in memory with name: no-name-2ffe2ab6-a6c8-4c4b-a5bb-37787ec96843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \t31    \n",
      "Finished Genetic Algorithm tuning. Time taken: 390.50 seconds\n",
      "\n",
      "Best parameters for Random Forest (Genetic Algorithm):\n",
      "n_estimators: 310\n",
      "max_depth: 106\n",
      "min_samples_split: 6\n",
      "min_samples_leaf: 2\n",
      "Best accuracy: 0.9472\n",
      "\n",
      "Evaluating Random Forest with Bayesian Optimization\n",
      "Starting Bayesian Optimization for Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 01:01:04,026] Trial 0 finished with value: 0.9333333333333333 and parameters: {'n_estimators': 495, 'max_depth': 32, 'min_samples_split': 12, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.9333333333333333.\n",
      "[I 2024-11-04 01:01:05,059] Trial 1 finished with value: 0.9388888888888889 and parameters: {'n_estimators': 283, 'max_depth': 47, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:01:05,174] Trial 2 finished with value: 0.8805555555555555 and parameters: {'n_estimators': 15, 'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:01:06,263] Trial 3 finished with value: 0.9277777777777778 and parameters: {'n_estimators': 303, 'max_depth': 39, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:01:06,937] Trial 4 finished with value: 0.9361111111111111 and parameters: {'n_estimators': 173, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:01:07,928] Trial 5 finished with value: 0.9361111111111111 and parameters: {'n_estimators': 274, 'max_depth': 8, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:01:09,558] Trial 6 finished with value: 0.9166666666666666 and parameters: {'n_estimators': 466, 'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:01:10,505] Trial 7 finished with value: 0.9361111111111111 and parameters: {'n_estimators': 254, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:01:11,287] Trial 8 finished with value: 0.925 and parameters: {'n_estimators': 150, 'max_depth': 25, 'min_samples_split': 17, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:01:11,590] Trial 9 finished with value: 0.9333333333333333 and parameters: {'n_estimators': 60, 'max_depth': 14, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:01:12,849] Trial 10 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 351, 'max_depth': 50, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.9416666666666667.\n",
      "[I 2024-11-04 01:01:14,068] Trial 11 finished with value: 0.9361111111111111 and parameters: {'n_estimators': 343, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.9416666666666667.\n",
      "[I 2024-11-04 01:01:15,456] Trial 12 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 389, 'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.9416666666666667.\n",
      "[I 2024-11-04 01:01:16,846] Trial 13 finished with value: 0.9388888888888889 and parameters: {'n_estimators': 393, 'max_depth': 37, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9416666666666667.\n",
      "[I 2024-11-04 01:01:18,275] Trial 14 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 407, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.9416666666666667.\n",
      "[I 2024-11-04 01:01:19,685] Trial 15 finished with value: 0.9388888888888889 and parameters: {'n_estimators': 400, 'max_depth': 41, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9416666666666667.\n",
      "[I 2024-11-04 01:01:20,440] Trial 16 finished with value: 0.9361111111111111 and parameters: {'n_estimators': 196, 'max_depth': 32, 'min_samples_split': 15, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.9416666666666667.\n",
      "[I 2024-11-04 01:01:21,695] Trial 17 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 353, 'max_depth': 33, 'min_samples_split': 20, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:22,977] Trial 18 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 356, 'max_depth': 32, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:23,760] Trial 19 finished with value: 0.9277777777777778 and parameters: {'n_estimators': 209, 'max_depth': 32, 'min_samples_split': 20, 'min_samples_leaf': 10}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:25,350] Trial 20 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 448, 'max_depth': 20, 'min_samples_split': 20, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:26,937] Trial 21 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 446, 'max_depth': 17, 'min_samples_split': 20, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:28,113] Trial 22 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 330, 'max_depth': 28, 'min_samples_split': 18, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:29,948] Trial 23 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 454, 'max_depth': 20, 'min_samples_split': 16, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:31,665] Trial 24 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 498, 'max_depth': 27, 'min_samples_split': 16, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:33,410] Trial 25 finished with value: 0.9361111111111111 and parameters: {'n_estimators': 496, 'max_depth': 26, 'min_samples_split': 15, 'min_samples_leaf': 4}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:34,926] Trial 26 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 432, 'max_depth': 14, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:36,576] Trial 27 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 475, 'max_depth': 22, 'min_samples_split': 17, 'min_samples_leaf': 3}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:37,892] Trial 28 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 370, 'max_depth': 36, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:39,629] Trial 29 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 493, 'max_depth': 28, 'min_samples_split': 17, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:41,114] Trial 30 finished with value: 0.9333333333333333 and parameters: {'n_estimators': 422, 'max_depth': 34, 'min_samples_split': 12, 'min_samples_leaf': 7}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:42,267] Trial 31 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 323, 'max_depth': 30, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:43,348] Trial 32 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 298, 'max_depth': 29, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:44,927] Trial 33 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 462, 'max_depth': 25, 'min_samples_split': 16, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:45,994] Trial 34 finished with value: 0.9361111111111111 and parameters: {'n_estimators': 238, 'max_depth': 18, 'min_samples_split': 19, 'min_samples_leaf': 3}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:47,169] Trial 35 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 324, 'max_depth': 43, 'min_samples_split': 16, 'min_samples_leaf': 5}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:48,289] Trial 36 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 310, 'max_depth': 29, 'min_samples_split': 19, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:49,613] Trial 37 finished with value: 0.9388888888888889 and parameters: {'n_estimators': 372, 'max_depth': 35, 'min_samples_split': 13, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:51,126] Trial 38 finished with value: 0.9361111111111111 and parameters: {'n_estimators': 425, 'max_depth': 21, 'min_samples_split': 19, 'min_samples_leaf': 4}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:52,847] Trial 39 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 498, 'max_depth': 13, 'min_samples_split': 16, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:53,861] Trial 40 finished with value: 0.9333333333333333 and parameters: {'n_estimators': 272, 'max_depth': 24, 'min_samples_split': 18, 'min_samples_leaf': 6}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:54,929] Trial 41 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 294, 'max_depth': 29, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:55,898] Trial 42 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 255, 'max_depth': 29, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:57,041] Trial 43 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 306, 'max_depth': 31, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:57,453] Trial 44 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 85, 'max_depth': 38, 'min_samples_split': 19, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:58,327] Trial 45 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 231, 'max_depth': 26, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:01:59,343] Trial 46 finished with value: 0.9361111111111111 and parameters: {'n_estimators': 270, 'max_depth': 34, 'min_samples_split': 16, 'min_samples_leaf': 3}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:01,000] Trial 47 finished with value: 0.9388888888888889 and parameters: {'n_estimators': 474, 'max_depth': 18, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:02,529] Trial 48 finished with value: 0.9305555555555556 and parameters: {'n_estimators': 376, 'max_depth': 23, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:03,742] Trial 49 finished with value: 0.9305555555555556 and parameters: {'n_estimators': 338, 'max_depth': 27, 'min_samples_split': 17, 'min_samples_leaf': 8}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:04,771] Trial 50 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 286, 'max_depth': 30, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:05,845] Trial 51 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 291, 'max_depth': 33, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:06,985] Trial 52 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 316, 'max_depth': 30, 'min_samples_split': 19, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:08,249] Trial 53 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 353, 'max_depth': 24, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:08,852] Trial 54 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 147, 'max_depth': 36, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:09,939] Trial 55 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 291, 'max_depth': 20, 'min_samples_split': 17, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:11,352] Trial 56 finished with value: 0.9388888888888889 and parameters: {'n_estimators': 401, 'max_depth': 27, 'min_samples_split': 15, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:12,913] Trial 57 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 442, 'max_depth': 31, 'min_samples_split': 18, 'min_samples_leaf': 3}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:13,830] Trial 58 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 235, 'max_depth': 39, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:14,633] Trial 59 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 209, 'max_depth': 42, 'min_samples_split': 19, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:16,149] Trial 60 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 415, 'max_depth': 16, 'min_samples_split': 16, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:17,166] Trial 61 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 270, 'max_depth': 29, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:18,314] Trial 62 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 248, 'max_depth': 33, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:19,515] Trial 63 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 333, 'max_depth': 1, 'min_samples_split': 19, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:20,467] Trial 64 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 256, 'max_depth': 28, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:21,227] Trial 65 finished with value: 0.9361111111111111 and parameters: {'n_estimators': 186, 'max_depth': 26, 'min_samples_split': 15, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:22,550] Trial 66 finished with value: 0.9305555555555556 and parameters: {'n_estimators': 359, 'max_depth': 30, 'min_samples_split': 20, 'min_samples_leaf': 10}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:24,170] Trial 67 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 460, 'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:25,249] Trial 68 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 296, 'max_depth': 23, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:26,926] Trial 69 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 483, 'max_depth': 47, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:28,293] Trial 70 finished with value: 0.9388888888888889 and parameters: {'n_estimators': 386, 'max_depth': 32, 'min_samples_split': 14, 'min_samples_leaf': 3}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:29,152] Trial 71 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 218, 'max_depth': 33, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:30,118] Trial 72 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 256, 'max_depth': 35, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:31,286] Trial 73 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 318, 'max_depth': 29, 'min_samples_split': 19, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:32,380] Trial 74 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 298, 'max_depth': 27, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:33,612] Trial 75 finished with value: 0.9388888888888889 and parameters: {'n_estimators': 282, 'max_depth': 37, 'min_samples_split': 16, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:34,840] Trial 76 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 342, 'max_depth': 25, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:36,034] Trial 77 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 323, 'max_depth': 31, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:37,159] Trial 78 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 309, 'max_depth': 34, 'min_samples_split': 15, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:37,819] Trial 79 finished with value: 0.9361111111111111 and parameters: {'n_estimators': 158, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:38,890] Trial 80 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 285, 'max_depth': 33, 'min_samples_split': 19, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:40,168] Trial 81 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 363, 'max_depth': 24, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.9472222222222222.\n",
      "[I 2024-11-04 01:02:41,420] Trial 82 finished with value: 0.95 and parameters: {'n_estimators': 345, 'max_depth': 24, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:42,412] Trial 83 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 265, 'max_depth': 28, 'min_samples_split': 16, 'min_samples_leaf': 1}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:43,673] Trial 84 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 345, 'max_depth': 22, 'min_samples_split': 17, 'min_samples_leaf': 2}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:44,871] Trial 85 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 328, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:45,993] Trial 86 finished with value: 0.9277777777777778 and parameters: {'n_estimators': 306, 'max_depth': 27, 'min_samples_split': 17, 'min_samples_leaf': 9}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:47,375] Trial 87 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 385, 'max_depth': 19, 'min_samples_split': 18, 'min_samples_leaf': 2}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:49,252] Trial 88 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 482, 'max_depth': 25, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:49,457] Trial 89 finished with value: 0.9361111111111111 and parameters: {'n_estimators': 22, 'max_depth': 32, 'min_samples_split': 19, 'min_samples_leaf': 1}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:50,399] Trial 90 finished with value: 0.9388888888888889 and parameters: {'n_estimators': 246, 'max_depth': 35, 'min_samples_split': 16, 'min_samples_leaf': 2}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:51,681] Trial 91 finished with value: 0.95 and parameters: {'n_estimators': 347, 'max_depth': 24, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:52,938] Trial 92 finished with value: 0.95 and parameters: {'n_estimators': 350, 'max_depth': 29, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:54,265] Trial 93 finished with value: 0.9472222222222222 and parameters: {'n_estimators': 373, 'max_depth': 23, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:55,533] Trial 94 finished with value: 0.9388888888888889 and parameters: {'n_estimators': 348, 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:56,887] Trial 95 finished with value: 0.9416666666666667 and parameters: {'n_estimators': 362, 'max_depth': 26, 'min_samples_split': 16, 'min_samples_leaf': 2}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:58,433] Trial 96 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 436, 'max_depth': 29, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:02:59,876] Trial 97 finished with value: 0.9444444444444444 and parameters: {'n_estimators': 414, 'max_depth': 21, 'min_samples_split': 17, 'min_samples_leaf': 2}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:03:01,106] Trial 98 finished with value: 0.9361111111111111 and parameters: {'n_estimators': 336, 'max_depth': 31, 'min_samples_split': 18, 'min_samples_leaf': 6}. Best is trial 82 with value: 0.95.\n",
      "[I 2024-11-04 01:03:02,302] Trial 99 finished with value: 0.9361111111111111 and parameters: {'n_estimators': 279, 'max_depth': 16, 'min_samples_split': 16, 'min_samples_leaf': 3}. Best is trial 82 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Bayesian Optimization tuning. Time taken: 119.99 seconds\n",
      "\n",
      "Best parameters for Random Forest (Bayesian Optimization):\n",
      "n_estimators: 345\n",
      "max_depth: 24\n",
      "min_samples_split: 17\n",
      "min_samples_leaf: 1\n",
      "Best accuracy: 0.9500\n",
      "\n",
      "Number of training samples: 840\n",
      "Number of testing samples: 360\n",
      "Total samples: 1200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from deap import base, creator, tools, algorithms\n",
    "import optuna\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "param_space = {\n",
    "    'n_estimators': list(range(10, 501, 10)),\n",
    "    'max_depth': [None] + list(range(5, 51, 5)),\n",
    "    'min_samples_split': list(range(2, 21)),\n",
    "    'min_samples_leaf': list(range(1, 11))\n",
    "}\n",
    "\n",
    "def prepare_data(X, y, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=360, train_size=840, stratify=y, random_state=random_state)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "def genetic_algorithm(X, y, random_state=42):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = prepare_data(X, y, random_state)\n",
    "\n",
    "    def evaluate(individual):\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=individual[0],\n",
    "            max_depth=individual[1],\n",
    "            min_samples_split=individual[2],\n",
    "            min_samples_leaf=individual[3],\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            clf.fit(X_train_scaled, y_train)\n",
    "            y_pred = clf.predict(X_test_scaled)\n",
    "            return accuracy_score(y_test, y_pred),\n",
    "        except Exception as e:\n",
    "            print(f\"Error during evaluation: {e}\")\n",
    "            return 0,\n",
    "\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_n_estimators\", random.choice, param_space['n_estimators'])\n",
    "    toolbox.register(\"attr_max_depth\", random.choice, param_space['max_depth'])\n",
    "    toolbox.register(\"attr_min_samples_split\", random.choice, param_space['min_samples_split'])\n",
    "    toolbox.register(\"attr_min_samples_leaf\", random.choice, param_space['min_samples_leaf'])\n",
    "    toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                     (toolbox.attr_n_estimators, toolbox.attr_max_depth, \n",
    "                      toolbox.attr_min_samples_split, toolbox.attr_min_samples_leaf), n=1)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutUniformInt, low=1, up=500, indpb=0.2)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population(n=50)\n",
    "    ngen = 10\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Starting Genetic Algorithm optimization for Random Forest...\")\n",
    "\n",
    "    result, log = algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=ngen, verbose=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Finished Genetic Algorithm tuning. Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    best_individual = tools.selBest(result, k=1)[0]\n",
    "    best_params = {\n",
    "        'n_estimators': best_individual[0],\n",
    "        'max_depth': best_individual[1],\n",
    "        'min_samples_split': best_individual[2],\n",
    "        'min_samples_leaf': best_individual[3]\n",
    "    }\n",
    "    best_accuracy = best_individual.fitness.values[0]\n",
    "\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "def bayesian_optimization(X, y, random_state=42):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = prepare_data(X, y, random_state)\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 10, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 50),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            'random_state': random_state,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "        if params['max_depth'] == 1:\n",
    "            params['max_depth'] = None\n",
    "        \n",
    "        clf = RandomForestClassifier(**params)\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Starting Bayesian Optimization for Random Forest...\")\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Finished Bayesian Optimization tuning. Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    best_params = study.best_params\n",
    "    if best_params['max_depth'] == 1:\n",
    "        best_params['max_depth'] = None\n",
    "    best_accuracy = study.best_value\n",
    "\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "# Main execution\n",
    "random_state = 42\n",
    "\n",
    "# Assuming X and y are your feature matrix and target vector\n",
    "# X = ...\n",
    "# y = ...\n",
    "\n",
    "print(\"Evaluating Random Forest with Genetic Algorithm Optimization\")\n",
    "ga_best_params, ga_best_accuracy = genetic_algorithm(X, y, random_state=random_state)\n",
    "print(\"\\nBest parameters for Random Forest (Genetic Algorithm):\")\n",
    "for param, value in ga_best_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best accuracy: {ga_best_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nEvaluating Random Forest with Bayesian Optimization\")\n",
    "bo_best_params, bo_best_accuracy = bayesian_optimization(X, y, random_state=random_state)\n",
    "print(\"\\nBest parameters for Random Forest (Bayesian Optimization):\")\n",
    "for param, value in bo_best_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best accuracy: {bo_best_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nNumber of training samples: 840\")\n",
    "print(f\"Number of testing samples: 360\")\n",
    "print(f\"Total samples: 1200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c085f7dc-be5c-4d53-aece-813d9204cbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression with Genetic Algorithm Optimization\n",
      "Starting Genetic Algorithm optimization for Logistic Regression...\n",
      "Error during evaluation: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "Error during evaluation: penalty=None is not supported for the liblinear solver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f20210934/.local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:497: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.38642e-17): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during evaluation: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "Error during evaluation: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "Error during evaluation: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "Error during evaluation: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "Error during evaluation: Solver newton-cholesky supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "Error during evaluation: l1_ratio must be specified when penalty is elasticnet.\n",
      "Error during evaluation: Solver newton-cholesky supports only 'l2' or None penalties, got l1 penalty.\n",
      "Error during evaluation: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "Error during evaluation: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "Error during evaluation: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "Error during evaluation: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "Error during evaluation: Solver newton-cholesky supports only 'l2' or None penalties, got l1 penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f20210934/.local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:497: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.38642e-17): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\n",
      "0  \t24    \n",
      "Error during evaluation: Solver newton-cholesky supports only 'l2' or None penalties, got l1 penalty.\n",
      "Error during evaluation: Solver newton-cholesky supports only 'l2' or None penalties, got l1 penalty.\n",
      "Error during evaluation: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "Error during evaluation: Solver newton-cholesky supports only 'l2' or None penalties, got l1 penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f20210934/.local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:497: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.38642e-17): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during evaluation: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "Error during evaluation: l1_ratio must be specified when penalty is elasticnet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f20210934/.local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:497: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.38642e-17): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during evaluation: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "Error during evaluation: l1_ratio must be specified when penalty is elasticnet.\n",
      "Error during evaluation: Solver newton-cholesky supports only 'l2' or None penalties, got l1 penalty.\n",
      "1  \t22    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f20210934/.local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:497: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.38642e-17): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during evaluation: Solver newton-cholesky supports only 'l2' or None penalties, got l1 penalty.\n",
      "2  \t13    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f20210934/.local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:497: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.38642e-17): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  \t16    \n",
      "Error during evaluation: penalty=None is not supported for the liblinear solver\n",
      "Error during evaluation: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "4  \t14    \n",
      "Error during evaluation: l1_ratio must be specified when penalty is elasticnet.\n",
      "Error during evaluation: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 01:06:04,274] A new study created in memory with name: no-name-135dfa51-d95e-4c14-b83b-71538509cf55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  \t14    \n",
      "Finished Genetic Algorithm tuning. Time taken: 181.85 seconds\n",
      "\n",
      "Best parameters for Logistic Regression (Genetic Algorithm):\n",
      "C: 0.1\n",
      "solver: saga\n",
      "max_iter: 200\n",
      "penalty: None\n",
      "Best accuracy: 0.9806\n",
      "\n",
      "Evaluating Logistic Regression with Bayesian Optimization\n",
      "Starting Bayesian Optimization for Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 01:06:04,872] Trial 0 finished with value: 0.9694444444444444 and parameters: {'C': 10, 'solver': 'newton-cg', 'max_iter': 2000, 'penalty': 'l1'}. Best is trial 0 with value: 0.9694444444444444.\n",
      "[I 2024-11-04 01:06:05,389] Trial 1 finished with value: 0.9694444444444444 and parameters: {'C': 10, 'solver': 'lbfgs', 'max_iter': 1000, 'penalty': 'l1'}. Best is trial 0 with value: 0.9694444444444444.\n",
      "[I 2024-11-04 01:06:10,554] Trial 2 finished with value: 0.9722222222222222 and parameters: {'C': 1, 'solver': 'sag', 'max_iter': 1000, 'penalty': None}. Best is trial 2 with value: 0.9722222222222222.\n",
      "[I 2024-11-04 01:06:11,022] Trial 3 finished with value: 0.9694444444444444 and parameters: {'C': 100, 'solver': 'newton-cg', 'max_iter': 200, 'penalty': None}. Best is trial 2 with value: 0.9722222222222222.\n",
      "[I 2024-11-04 01:06:15,428] Trial 4 finished with value: 0.975 and parameters: {'C': 100, 'solver': 'saga', 'max_iter': 500, 'penalty': 'elasticnet', 'l1_ratio': 0.17727773776879552}. Best is trial 4 with value: 0.975.\n",
      "[I 2024-11-04 01:06:15,927] Trial 5 finished with value: 0.9694444444444444 and parameters: {'C': 0.01, 'solver': 'newton-cg', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 4 with value: 0.975.\n",
      "[I 2024-11-04 01:06:15,930] Trial 6 finished with value: 0.0 and parameters: {'C': 10, 'solver': 'sag', 'max_iter': 1000, 'penalty': 'elasticnet', 'l1_ratio': 0.4953579946792499}. Best is trial 4 with value: 0.975.\n",
      "[I 2024-11-04 01:06:15,933] Trial 7 finished with value: 0.0 and parameters: {'C': 10, 'solver': 'lbfgs', 'max_iter': 1000, 'penalty': 'elasticnet', 'l1_ratio': 0.9786420293977439}. Best is trial 4 with value: 0.975.\n",
      "[I 2024-11-04 01:06:15,935] Trial 8 finished with value: 0.0 and parameters: {'C': 0.001, 'solver': 'lbfgs', 'max_iter': 500, 'penalty': 'elasticnet', 'l1_ratio': 0.31542654745914}. Best is trial 4 with value: 0.975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during evaluation: Solver sag supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "Error during evaluation: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "Error during evaluation: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 01:06:19,038] Trial 9 finished with value: 0.975 and parameters: {'C': 10, 'solver': 'sag', 'max_iter': 500, 'penalty': 'l1'}. Best is trial 4 with value: 0.975.\n",
      "[I 2024-11-04 01:06:22,680] Trial 10 finished with value: 0.9777777777777777 and parameters: {'C': 0.1, 'solver': 'saga', 'max_iter': 500, 'penalty': 'l2'}. Best is trial 10 with value: 0.9777777777777777.\n",
      "[I 2024-11-04 01:06:26,096] Trial 11 finished with value: 0.9777777777777777 and parameters: {'C': 0.1, 'solver': 'saga', 'max_iter': 500, 'penalty': 'l2'}. Best is trial 10 with value: 0.9777777777777777.\n",
      "[I 2024-11-04 01:06:29,892] Trial 12 finished with value: 0.9777777777777777 and parameters: {'C': 0.1, 'solver': 'saga', 'max_iter': 500, 'penalty': 'l2'}. Best is trial 10 with value: 0.9777777777777777.\n",
      "[I 2024-11-04 01:06:30,030] Trial 13 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 500, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:30,161] Trial 14 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:30,409] Trial 15 finished with value: 0.9666666666666667 and parameters: {'C': 1000, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:30,540] Trial 16 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:30,653] Trial 17 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:31,183] Trial 18 finished with value: 0.9694444444444444 and parameters: {'C': 0.01, 'solver': 'newton-cholesky', 'max_iter': 200, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:31,240] Trial 19 finished with value: 0.9055555555555556 and parameters: {'C': 0.001, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': None}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:31,390] Trial 20 finished with value: 0.9805555555555555 and parameters: {'C': 1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:31,500] Trial 21 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:31,610] Trial 22 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:31,720] Trial 23 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:32,420] Trial 24 finished with value: 0.9694444444444444 and parameters: {'C': 1000, 'solver': 'newton-cholesky', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:32,532] Trial 25 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 200, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:32,642] Trial 26 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:32,752] Trial 27 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': None}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:32,805] Trial 28 finished with value: 0.95 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l1'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:32,811] Trial 29 finished with value: 0.0 and parameters: {'C': 1000, 'solver': 'newton-cholesky', 'max_iter': 2000, 'penalty': 'l1'}. Best is trial 13 with value: 0.9805555555555555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during evaluation: Solver newton-cholesky supports only 'l2' or None penalties, got l1 penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 01:06:33,360] Trial 30 finished with value: 0.9694444444444444 and parameters: {'C': 0.01, 'solver': 'newton-cg', 'max_iter': 500, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:33,472] Trial 31 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:33,583] Trial 32 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:33,732] Trial 33 finished with value: 0.9805555555555555 and parameters: {'C': 1, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:33,913] Trial 34 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:34,370] Trial 35 finished with value: 0.95 and parameters: {'C': 0.1, 'solver': 'lbfgs', 'max_iter': 200, 'penalty': None}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:34,426] Trial 36 finished with value: 0.95 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 1000, 'penalty': 'l1'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:35,285] Trial 37 finished with value: 0.9805555555555555 and parameters: {'C': 100, 'solver': 'sag', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:35,300] Trial 38 finished with value: 0.0 and parameters: {'C': 0.1, 'solver': 'newton-cg', 'max_iter': 1000, 'penalty': 'elasticnet', 'l1_ratio': 0.9652684898573339}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:35,361] Trial 39 finished with value: 0.9055555555555556 and parameters: {'C': 0.001, 'solver': 'liblinear', 'max_iter': 500, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during evaluation: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 01:06:35,816] Trial 40 finished with value: 0.95 and parameters: {'C': 1, 'solver': 'lbfgs', 'max_iter': 100, 'penalty': None}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:35,978] Trial 41 finished with value: 0.9805555555555555 and parameters: {'C': 1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:36,137] Trial 42 finished with value: 0.9805555555555555 and parameters: {'C': 1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:36,302] Trial 43 finished with value: 0.9805555555555555 and parameters: {'C': 1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'elasticnet', 'l1_ratio': 0.006405069042841327}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:46,153] Trial 44 finished with value: 0.9722222222222222 and parameters: {'C': 10, 'solver': 'sag', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:46,340] Trial 45 finished with value: 0.9805555555555555 and parameters: {'C': 1, 'solver': 'liblinear', 'max_iter': 500, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:48,782] Trial 46 finished with value: 0.9694444444444444 and parameters: {'C': 0.01, 'solver': 'saga', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:49,284] Trial 47 finished with value: 0.9777777777777777 and parameters: {'C': 0.1, 'solver': 'newton-cg', 'max_iter': 500, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:49,359] Trial 48 finished with value: 0.9055555555555556 and parameters: {'C': 0.001, 'solver': 'liblinear', 'max_iter': 1000, 'penalty': 'elasticnet', 'l1_ratio': 0.7376283940932736}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:49,503] Trial 49 finished with value: 0.9666666666666667 and parameters: {'C': 10, 'solver': 'liblinear', 'max_iter': 200, 'penalty': 'l1'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:50,199] Trial 50 finished with value: 0.9722222222222222 and parameters: {'C': 100, 'solver': 'newton-cholesky', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:50,315] Trial 51 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:50,428] Trial 52 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:50,540] Trial 53 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:50,651] Trial 54 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:54,823] Trial 55 finished with value: 0.9777777777777777 and parameters: {'C': 0.1, 'solver': 'saga', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:55,255] Trial 56 finished with value: 0.95 and parameters: {'C': 1000, 'solver': 'lbfgs', 'max_iter': 500, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:55,352] Trial 57 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': None}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:57,575] Trial 58 finished with value: 0.9777777777777777 and parameters: {'C': 0.1, 'solver': 'sag', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:57,682] Trial 59 finished with value: 0.9611111111111111 and parameters: {'C': 0.01, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:57,814] Trial 60 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 500, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:57,947] Trial 61 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:58,079] Trial 62 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:58,212] Trial 63 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:59,046] Trial 64 finished with value: 0.9777777777777777 and parameters: {'C': 0.1, 'solver': 'newton-cholesky', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:59,162] Trial 65 finished with value: 0.9777777777777777 and parameters: {'C': 1000, 'solver': 'liblinear', 'max_iter': 200, 'penalty': 'l1'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:59,296] Trial 66 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:59,312] Trial 67 finished with value: 0.0 and parameters: {'C': 0.001, 'solver': 'newton-cg', 'max_iter': 2000, 'penalty': 'elasticnet', 'l1_ratio': 0.6095724581483165}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:06:59,495] Trial 68 finished with value: 0.9805555555555555 and parameters: {'C': 1, 'solver': 'liblinear', 'max_iter': 1000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during evaluation: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 01:07:12,870] Trial 69 finished with value: 0.9722222222222222 and parameters: {'C': 10, 'solver': 'saga', 'max_iter': 2000, 'penalty': None}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:13,007] Trial 70 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 500, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:13,139] Trial 71 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:13,271] Trial 72 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:13,402] Trial 73 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:13,534] Trial 74 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:14,097] Trial 75 finished with value: 0.95 and parameters: {'C': 100, 'solver': 'lbfgs', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:19,041] Trial 76 finished with value: 0.9805555555555555 and parameters: {'C': 1, 'solver': 'sag', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:19,109] Trial 77 finished with value: 0.95 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 200, 'penalty': 'l1'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:19,215] Trial 78 finished with value: 0.9611111111111111 and parameters: {'C': 0.01, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:19,355] Trial 79 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'elasticnet', 'l1_ratio': 0.36499881225007424}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:20,150] Trial 80 finished with value: 0.9777777777777777 and parameters: {'C': 0.1, 'solver': 'newton-cholesky', 'max_iter': 500, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:20,264] Trial 81 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 200, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:20,376] Trial 82 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 200, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:20,487] Trial 83 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 200, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:20,987] Trial 84 finished with value: 0.9777777777777777 and parameters: {'C': 1, 'solver': 'newton-cg', 'max_iter': 200, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:21,121] Trial 85 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 1000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:21,189] Trial 86 finished with value: 0.9055555555555556 and parameters: {'C': 0.001, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': None}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:21,321] Trial 87 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:21,570] Trial 88 finished with value: 0.9666666666666667 and parameters: {'C': 1000, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:25,198] Trial 89 finished with value: 0.975 and parameters: {'C': 10, 'solver': 'saga', 'max_iter': 500, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:25,383] Trial 90 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:25,495] Trial 91 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:25,606] Trial 92 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:25,718] Trial 93 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:26,237] Trial 94 finished with value: 0.9777777777777777 and parameters: {'C': 0.1, 'solver': 'lbfgs', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:26,291] Trial 95 finished with value: 0.95 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 2000, 'penalty': 'l1'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:31,081] Trial 96 finished with value: 0.9805555555555555 and parameters: {'C': 1, 'solver': 'sag', 'max_iter': 2000, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:31,220] Trial 97 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 100, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:31,358] Trial 98 finished with value: 0.9805555555555555 and parameters: {'C': 0.1, 'solver': 'liblinear', 'max_iter': 200, 'penalty': 'elasticnet', 'l1_ratio': 0.7540287614216983}. Best is trial 13 with value: 0.9805555555555555.\n",
      "[I 2024-11-04 01:07:32,157] Trial 99 finished with value: 0.9694444444444444 and parameters: {'C': 0.01, 'solver': 'newton-cholesky', 'max_iter': 500, 'penalty': 'l2'}. Best is trial 13 with value: 0.9805555555555555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Bayesian Optimization tuning. Time taken: 87.88 seconds\n",
      "\n",
      "Best parameters for Logistic Regression (Bayesian Optimization):\n",
      "C: 0.1\n",
      "solver: liblinear\n",
      "max_iter: 500\n",
      "penalty: l2\n",
      "Best accuracy: 0.9806\n",
      "\n",
      "Number of training samples: 840\n",
      "Number of testing samples: 360\n",
      "Total samples: 1200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from deap import base, creator, tools, algorithms\n",
    "import optuna\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the parameter spaces for Logistic Regression\n",
    "param_space = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "    'max_iter': [100, 200, 500, 1000, 2000],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet', None]\n",
    "}\n",
    "\n",
    "def safe_choice(options, index):\n",
    "    return options[index % len(options)]\n",
    "\n",
    "def prepare_data(X, y, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=360, train_size=840, stratify=y, random_state=random_state)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "def genetic_algorithm(X, y, random_state=42):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = prepare_data(X, y, random_state)\n",
    "\n",
    "    def evaluate(individual):\n",
    "        clf = LogisticRegression(\n",
    "            C=safe_choice(param_space['C'], individual[0]),\n",
    "            solver=safe_choice(param_space['solver'], individual[1]),\n",
    "            max_iter=safe_choice(param_space['max_iter'], individual[2]),\n",
    "            penalty=safe_choice(param_space['penalty'], individual[3]),\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            clf.fit(X_train_scaled, y_train)\n",
    "            y_pred = clf.predict(X_test_scaled)\n",
    "            return accuracy_score(y_test, y_pred),\n",
    "        except Exception as e:\n",
    "            print(f\"Error during evaluation: {e}\")\n",
    "            return 0,\n",
    "\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_C\", random.randint, 0, len(param_space['C'])-1)\n",
    "    toolbox.register(\"attr_solver\", random.randint, 0, len(param_space['solver'])-1)\n",
    "    toolbox.register(\"attr_max_iter\", random.randint, 0, len(param_space['max_iter'])-1)\n",
    "    toolbox.register(\"attr_penalty\", random.randint, 0, len(param_space['penalty'])-1)\n",
    "    toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                     (toolbox.attr_C, toolbox.attr_solver, \n",
    "                      toolbox.attr_max_iter, toolbox.attr_penalty), n=1)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=10, indpb=0.2)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population(n=24)\n",
    "    ngen = 5\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Starting Genetic Algorithm optimization for Logistic Regression...\")\n",
    "\n",
    "    result, log = algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=ngen, verbose=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Finished Genetic Algorithm tuning. Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    best_individual = tools.selBest(result, k=1)[0]\n",
    "    best_params = {\n",
    "        'C': safe_choice(param_space['C'], best_individual[0]),\n",
    "        'solver': safe_choice(param_space['solver'], best_individual[1]),\n",
    "        'max_iter': safe_choice(param_space['max_iter'], best_individual[2]),\n",
    "        'penalty': safe_choice(param_space['penalty'], best_individual[3]),\n",
    "    }\n",
    "    best_accuracy = best_individual.fitness.values[0]\n",
    "\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "def bayesian_optimization(X, y, random_state=42):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = prepare_data(X, y, random_state)\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'C': trial.suggest_categorical('C', param_space['C']),\n",
    "            'solver': trial.suggest_categorical('solver', param_space['solver']),\n",
    "            'max_iter': trial.suggest_categorical('max_iter', param_space['max_iter']),\n",
    "            'penalty': trial.suggest_categorical('penalty', param_space['penalty']),\n",
    "            'random_state': random_state,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "        # Handle the elasticnet case\n",
    "        if params['penalty'] == 'elasticnet':\n",
    "            params['l1_ratio'] = trial.suggest_uniform('l1_ratio', 0, 1)\n",
    "        \n",
    "        # Handle solver-penalty incompatibilities\n",
    "        if params['solver'] == 'liblinear' and params['penalty'] not in ['l1', 'l2']:\n",
    "            params['penalty'] = 'l2'\n",
    "        elif params['solver'] in ['newton-cg', 'sag', 'lbfgs'] and params['penalty'] == 'l1':\n",
    "            params['penalty'] = 'l2'\n",
    "        \n",
    "        try:\n",
    "            clf = LogisticRegression(**params)\n",
    "            clf.fit(X_train_scaled, y_train)\n",
    "            y_pred = clf.predict(X_test_scaled)\n",
    "            return accuracy_score(y_test, y_pred)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during evaluation: {e}\")\n",
    "            return 0  # Return a low score for failed trials\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Starting Bayesian Optimization for Logistic Regression...\")\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Finished Bayesian Optimization tuning. Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_accuracy = study.best_value\n",
    "\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "# Main execution\n",
    "random_state = 42\n",
    "\n",
    "# Assuming X and y are your feature matrix and target vector\n",
    "# X = ...\n",
    "# y = ...\n",
    "\n",
    "print(\"Evaluating Logistic Regression with Genetic Algorithm Optimization\")\n",
    "ga_best_params, ga_best_accuracy = genetic_algorithm(X, y, random_state=random_state)\n",
    "print(\"\\nBest parameters for Logistic Regression (Genetic Algorithm):\")\n",
    "for param, value in ga_best_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best accuracy: {ga_best_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nEvaluating Logistic Regression with Bayesian Optimization\")\n",
    "bo_best_params, bo_best_accuracy = bayesian_optimization(X, y, random_state=random_state)\n",
    "print(\"\\nBest parameters for Logistic Regression (Bayesian Optimization):\")\n",
    "for param, value in bo_best_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best accuracy: {bo_best_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nNumber of training samples: 840\")\n",
    "print(f\"Number of testing samples: 360\")\n",
    "print(f\"Total samples: 1200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "786c3fa1-940a-4f69-a35f-2da9f749009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating SVM\n",
      "Genetic Algorithm Optimization\n",
      "Starting Genetic Algorithm optimization for SVM...\n",
      "gen\tnevals\n",
      "0  \t50    \n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 10 instead.\n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 1 instead.\n",
      "1  \t29    \n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 5 instead.\n",
      "Error during evaluation: The 'C' parameter of SVC must be a float in the range (0.0, inf). Got 0 instead.\n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 10 instead.\n",
      "2  \t32    \n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 9 instead.\n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 10 instead.\n",
      "3  \t31    \n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 5 instead.\n",
      "Error during evaluation: The 'C' parameter of SVC must be a float in the range (0.0, inf). Got 0 instead.\n",
      "4  \t27    \n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 7 instead.\n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 0 instead.\n",
      "5  \t23    \n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 4 instead.\n",
      "6  \t35    \n",
      "7  \t28    \n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 3 instead.\n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 2 instead.\n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 1 instead.\n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 1 instead.\n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 1 instead.\n",
      "8  \t29    \n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 10 instead.\n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 8 instead.\n",
      "9  \t35    \n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 8 instead.\n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 7 instead.\n",
      "Error during evaluation: The 'kernel' parameter of SVC must be a str among {'linear', 'precomputed', 'sigmoid', 'poly', 'rbf'} or a callable. Got 8 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 01:07:54,213] A new study created in memory with name: no-name-acdf771b-ac44-4608-b446-ce406e3a6c52\n",
      "[I 2024-11-04 01:07:54,339] Trial 0 finished with value: 0.8388888888888889 and parameters: {'C': 0.1, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 0 with value: 0.8388888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \t25    \n",
      "Finished Genetic Algorithm tuning. Time taken: 21.95 seconds\n",
      "\n",
      "Best parameters for SVM (Genetic Algorithm):\n",
      "C: 100\n",
      "kernel: sigmoid\n",
      "gamma: 0.0001\n",
      "degree: 3\n",
      "Best accuracy: 0.9778\n",
      "\n",
      "Bayesian Optimization\n",
      "Starting Bayesian Optimization for SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 01:07:54,625] Trial 1 finished with value: 0.55 and parameters: {'C': 10, 'kernel': 'rbf', 'gamma': 0.1}. Best is trial 0 with value: 0.8388888888888889.\n",
      "[I 2024-11-04 01:07:54,719] Trial 2 finished with value: 0.95 and parameters: {'C': 0.1, 'kernel': 'poly', 'gamma': 0.1, 'degree': 4}. Best is trial 2 with value: 0.95.\n",
      "[I 2024-11-04 01:07:54,821] Trial 3 finished with value: 0.9194444444444444 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 5}. Best is trial 2 with value: 0.95.\n",
      "[I 2024-11-04 01:07:54,880] Trial 4 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:55,128] Trial 5 finished with value: 0.9527777777777777 and parameters: {'C': 1, 'kernel': 'rbf', 'gamma': 0.01}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:55,204] Trial 6 finished with value: 0.7638888888888888 and parameters: {'C': 100, 'kernel': 'sigmoid', 'gamma': 0.1}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:55,493] Trial 7 finished with value: 0.5055555555555555 and parameters: {'C': 1, 'kernel': 'rbf', 'gamma': 1}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:55,718] Trial 8 finished with value: 0.5305555555555556 and parameters: {'C': 0.1, 'kernel': 'poly', 'gamma': 0.0001, 'degree': 4}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:55,820] Trial 9 finished with value: 0.9194444444444444 and parameters: {'C': 10, 'kernel': 'poly', 'gamma': 0.01, 'degree': 5}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:55,874] Trial 10 finished with value: 0.9583333333333334 and parameters: {'C': 100, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:55,928] Trial 11 finished with value: 0.9583333333333334 and parameters: {'C': 100, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:55,982] Trial 12 finished with value: 0.9583333333333334 and parameters: {'C': 100, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,035] Trial 13 finished with value: 0.9583333333333334 and parameters: {'C': 100, 'kernel': 'linear', 'gamma': 0.001}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,123] Trial 14 finished with value: 0.7583333333333333 and parameters: {'C': 100, 'kernel': 'sigmoid', 'gamma': 1}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,177] Trial 15 finished with value: 0.9583333333333334 and parameters: {'C': 100, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,229] Trial 16 finished with value: 0.9583333333333334 and parameters: {'C': 100, 'kernel': 'linear', 'gamma': 0.0001}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,306] Trial 17 finished with value: 0.9527777777777777 and parameters: {'C': 1, 'kernel': 'sigmoid', 'gamma': 0.001}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,358] Trial 18 finished with value: 0.9583333333333334 and parameters: {'C': 10, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,422] Trial 19 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,487] Trial 20 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,551] Trial 21 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,615] Trial 22 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,679] Trial 23 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,762] Trial 24 finished with value: 0.9555555555555556 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 3}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,827] Trial 25 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,909] Trial 26 finished with value: 0.9555555555555556 and parameters: {'C': 0.1, 'kernel': 'poly', 'gamma': 1, 'degree': 3}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:56,974] Trial 27 finished with value: 0.9638888888888889 and parameters: {'C': 10, 'kernel': 'poly', 'gamma': 1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:57,056] Trial 28 finished with value: 0.9555555555555556 and parameters: {'C': 1, 'kernel': 'poly', 'gamma': 1, 'degree': 3}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:57,186] Trial 29 finished with value: 0.8444444444444444 and parameters: {'C': 0.1, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:57,291] Trial 30 finished with value: 0.9111111111111111 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:57,356] Trial 31 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:57,421] Trial 32 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:57,713] Trial 33 finished with value: 0.5055555555555555 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 1}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:57,778] Trial 34 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 0.1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:57,861] Trial 35 finished with value: 0.9555555555555556 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 0.01, 'degree': 3}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:57,952] Trial 36 finished with value: 0.7555555555555555 and parameters: {'C': 10, 'kernel': 'sigmoid', 'gamma': 1}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:58,086] Trial 37 finished with value: 0.875 and parameters: {'C': 0.1, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:58,151] Trial 38 finished with value: 0.9638888888888889 and parameters: {'C': 1, 'kernel': 'poly', 'gamma': 0.1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:58,234] Trial 39 finished with value: 0.9555555555555556 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:58,526] Trial 40 finished with value: 0.5055555555555555 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 1}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:58,592] Trial 41 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:58,656] Trial 42 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:58,721] Trial 43 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:58,786] Trial 44 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 0.01, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:58,851] Trial 45 finished with value: 0.9638888888888889 and parameters: {'C': 100, 'kernel': 'poly', 'gamma': 1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:58,940] Trial 46 finished with value: 0.7583333333333333 and parameters: {'C': 100, 'kernel': 'sigmoid', 'gamma': 1}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:59,087] Trial 47 finished with value: 0.8444444444444444 and parameters: {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:59,170] Trial 48 finished with value: 0.9555555555555556 and parameters: {'C': 1, 'kernel': 'poly', 'gamma': 1, 'degree': 3}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:59,235] Trial 49 finished with value: 0.9638888888888889 and parameters: {'C': 0.1, 'kernel': 'poly', 'gamma': 0.1, 'degree': 2}. Best is trial 4 with value: 0.9638888888888889.\n",
      "[I 2024-11-04 01:07:59,307] Trial 50 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:07:59,378] Trial 51 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:07:59,450] Trial 52 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:07:59,521] Trial 53 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:07:59,593] Trial 54 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:07:59,665] Trial 55 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:07:59,736] Trial 56 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:07:59,808] Trial 57 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:07:59,879] Trial 58 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:07:59,951] Trial 59 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:00,022] Trial 60 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:00,094] Trial 61 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:00,165] Trial 62 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:00,237] Trial 63 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:00,309] Trial 64 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:00,380] Trial 65 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:00,450] Trial 66 finished with value: 0.9666666666666667 and parameters: {'C': 10, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:00,536] Trial 67 finished with value: 0.95 and parameters: {'C': 1, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:00,608] Trial 68 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:00,680] Trial 69 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:00,818] Trial 70 finished with value: 0.8916666666666667 and parameters: {'C': 0.1, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:00,890] Trial 71 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:00,962] Trial 72 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:01,034] Trial 73 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:01,105] Trial 74 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:01,177] Trial 75 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:01,249] Trial 76 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:01,321] Trial 77 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:01,374] Trial 78 finished with value: 0.9583333333333334 and parameters: {'C': 100, 'kernel': 'linear', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:01,451] Trial 79 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:01,521] Trial 80 finished with value: 0.9666666666666667 and parameters: {'C': 10, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:01,593] Trial 81 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:01,665] Trial 82 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:01,736] Trial 83 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:01,989] Trial 84 finished with value: 0.9583333333333334 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.01}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:02,030] Trial 85 finished with value: 0.9166666666666666 and parameters: {'C': 100, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:02,155] Trial 86 finished with value: 0.8833333333333333 and parameters: {'C': 1, 'kernel': 'rbf', 'gamma': 0.0001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:02,227] Trial 87 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:02,361] Trial 88 finished with value: 0.875 and parameters: {'C': 0.1, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:02,415] Trial 89 finished with value: 0.9583333333333334 and parameters: {'C': 100, 'kernel': 'linear', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:02,486] Trial 90 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:02,558] Trial 91 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:02,630] Trial 92 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:02,702] Trial 93 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:02,990] Trial 94 finished with value: 0.55 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.1}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:03,062] Trial 95 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:03,134] Trial 96 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:03,174] Trial 97 finished with value: 0.9166666666666666 and parameters: {'C': 100, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:03,246] Trial 98 finished with value: 0.9666666666666667 and parameters: {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}. Best is trial 50 with value: 0.9666666666666667.\n",
      "[I 2024-11-04 01:08:03,499] Trial 99 finished with value: 0.9583333333333334 and parameters: {'C': 10, 'kernel': 'rbf', 'gamma': 0.01}. Best is trial 50 with value: 0.9666666666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Bayesian Optimization tuning. Time taken: 9.29 seconds\n",
      "\n",
      "Best parameters for SVM (Bayesian Optimization):\n",
      "C: 100\n",
      "kernel: rbf\n",
      "gamma: 0.001\n",
      "Best accuracy: 0.9667\n",
      "\n",
      "Evaluating KNN\n",
      "Genetic Algorithm Optimization\n",
      "Starting Genetic Algorithm optimization for KNN...\n",
      "gen\tnevals\n",
      "0  \t50    \n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 5 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 1 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 2 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 2 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 7 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 6 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 2 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 7 instead.\n",
      "1  \t35    \n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 9 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 10 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 4 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 5 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 7 instead.\n",
      "2  \t29    \n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 3 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 8 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 2 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 3 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 1 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 4 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 10 instead.\n",
      "3  \t31    \n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 0 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 4 instead.\n",
      "4  \t24    \n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 2 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 8 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 9 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 10 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 10 instead.\n",
      "5  \t30    \n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 9 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 1 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 7 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 1 instead.\n",
      "6  \t29    \n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 3 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 9 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 0 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 4 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 7 instead.\n",
      "7  \t31    \n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 10 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 5 instead.\n",
      "8  \t34    \n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 8 instead.\n",
      "Error during evaluation: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 6 instead.\n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 4 instead.\n",
      "9  \t42    \n",
      "Error during evaluation: The 'algorithm' parameter of KNeighborsClassifier must be a str among {'kd_tree', 'brute', 'ball_tree', 'auto'}. Got 10 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 01:11:55,237] A new study created in memory with name: no-name-7bfa729c-bea8-4ff8-a512-106cc4ab83ab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \t29    \n",
      "Finished Genetic Algorithm tuning. Time taken: 231.69 seconds\n",
      "\n",
      "Best parameters for KNN (Genetic Algorithm):\n",
      "n_neighbors: 2\n",
      "weights: distance\n",
      "algorithm: auto\n",
      "p: 3\n",
      "Best accuracy: 0.9444\n",
      "\n",
      "Bayesian Optimization\n",
      "Starting Bayesian Optimization for KNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 01:11:55,613] Trial 0 finished with value: 0.8972222222222223 and parameters: {'n_neighbors': 29, 'weights': 'distance', 'algorithm': 'kd_tree', 'p': 2}. Best is trial 0 with value: 0.8972222222222223.\n",
      "[I 2024-11-04 01:11:55,716] Trial 1 finished with value: 0.9083333333333333 and parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'brute', 'p': 1}. Best is trial 1 with value: 0.9083333333333333.\n",
      "[I 2024-11-04 01:11:55,812] Trial 2 finished with value: 0.9111111111111111 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'algorithm': 'brute', 'p': 1}. Best is trial 2 with value: 0.9111111111111111.\n",
      "[I 2024-11-04 01:11:56,192] Trial 3 finished with value: 0.8916666666666667 and parameters: {'n_neighbors': 24, 'weights': 'uniform', 'algorithm': 'kd_tree', 'p': 1}. Best is trial 2 with value: 0.9111111111111111.\n",
      "[I 2024-11-04 01:11:56,221] Trial 4 finished with value: 0.9305555555555556 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'p': 2}. Best is trial 4 with value: 0.9305555555555556.\n",
      "[I 2024-11-04 01:11:56,528] Trial 5 finished with value: 0.9 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 4 with value: 0.9305555555555556.\n",
      "[I 2024-11-04 01:11:56,559] Trial 6 finished with value: 0.8916666666666667 and parameters: {'n_neighbors': 24, 'weights': 'uniform', 'algorithm': 'brute', 'p': 2}. Best is trial 4 with value: 0.9305555555555556.\n",
      "[I 2024-11-04 01:11:56,577] Trial 7 finished with value: 0.8944444444444445 and parameters: {'n_neighbors': 26, 'weights': 'distance', 'algorithm': 'brute', 'p': 2}. Best is trial 4 with value: 0.9305555555555556.\n",
      "[I 2024-11-04 01:11:56,600] Trial 8 finished with value: 0.8944444444444445 and parameters: {'n_neighbors': 22, 'weights': 'uniform', 'algorithm': 'auto', 'p': 2}. Best is trial 4 with value: 0.9305555555555556.\n",
      "[I 2024-11-04 01:11:56,738] Trial 9 finished with value: 0.9111111111111111 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'auto', 'p': 1}. Best is trial 4 with value: 0.9305555555555556.\n",
      "[I 2024-11-04 01:11:57,047] Trial 10 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 4 with value: 0.9305555555555556.\n",
      "[I 2024-11-04 01:11:57,350] Trial 11 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:11:57,660] Trial 12 finished with value: 0.9194444444444444 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:11:57,970] Trial 13 finished with value: 0.9305555555555556 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:11:58,003] Trial 14 finished with value: 0.9305555555555556 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:11:58,306] Trial 15 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:11:58,618] Trial 16 finished with value: 0.9166666666666666 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:11:58,921] Trial 17 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:11:59,221] Trial 18 finished with value: 0.9166666666666666 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'ball_tree', 'p': 1}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:11:59,530] Trial 19 finished with value: 0.9305555555555556 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:11:59,906] Trial 20 finished with value: 0.9027777777777778 and parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'kd_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:00,209] Trial 21 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:00,518] Trial 22 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:00,822] Trial 23 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:00,856] Trial 24 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'auto', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:01,165] Trial 25 finished with value: 0.9305555555555556 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:01,477] Trial 26 finished with value: 0.9222222222222223 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:01,774] Trial 27 finished with value: 0.9277777777777778 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'p': 1}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:02,086] Trial 28 finished with value: 0.9166666666666666 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:02,435] Trial 29 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:02,468] Trial 30 finished with value: 0.9166666666666666 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'algorithm': 'auto', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:02,787] Trial 31 finished with value: 0.8888888888888888 and parameters: {'n_neighbors': 30, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:03,091] Trial 32 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:03,400] Trial 33 finished with value: 0.9222222222222223 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:03,771] Trial 34 finished with value: 0.9111111111111111 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'algorithm': 'kd_tree', 'p': 1}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:04,082] Trial 35 finished with value: 0.925 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:04,392] Trial 36 finished with value: 0.9194444444444444 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 1}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:04,697] Trial 37 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:05,055] Trial 38 finished with value: 0.9305555555555556 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:05,173] Trial 39 finished with value: 0.9222222222222223 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:05,487] Trial 40 finished with value: 0.8916666666666667 and parameters: {'n_neighbors': 27, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 1}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:05,791] Trial 41 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:06,101] Trial 42 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:06,412] Trial 43 finished with value: 0.9305555555555556 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:06,456] Trial 44 finished with value: 0.9222222222222223 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:06,762] Trial 45 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:06,813] Trial 46 finished with value: 0.8916666666666667 and parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'brute', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:07,124] Trial 47 finished with value: 0.925 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:07,425] Trial 48 finished with value: 0.9222222222222223 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:07,734] Trial 49 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:07,885] Trial 50 finished with value: 0.9194444444444444 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'p': 1}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:08,235] Trial 51 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:08,590] Trial 52 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:08,948] Trial 53 finished with value: 0.9222222222222223 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:09,298] Trial 54 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:09,657] Trial 55 finished with value: 0.9305555555555556 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'kd_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:09,693] Trial 56 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'auto', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:09,991] Trial 57 finished with value: 0.9222222222222223 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:10,302] Trial 58 finished with value: 0.9305555555555556 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:10,616] Trial 59 finished with value: 0.9166666666666666 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:10,983] Trial 60 finished with value: 0.9222222222222223 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:11,288] Trial 61 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:11,592] Trial 62 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:11,901] Trial 63 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:12,211] Trial 64 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:12,521] Trial 65 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:12,837] Trial 66 finished with value: 0.9 and parameters: {'n_neighbors': 17, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:13,148] Trial 67 finished with value: 0.9194444444444444 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 1}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:13,442] Trial 68 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:13,477] Trial 69 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'auto', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:13,508] Trial 70 finished with value: 0.9305555555555556 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:13,813] Trial 71 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:14,123] Trial 72 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:14,429] Trial 73 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:14,741] Trial 74 finished with value: 0.9222222222222223 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:15,056] Trial 75 finished with value: 0.8916666666666667 and parameters: {'n_neighbors': 24, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:15,366] Trial 76 finished with value: 0.9111111111111111 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 1}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:15,677] Trial 77 finished with value: 0.925 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:16,045] Trial 78 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:16,343] Trial 79 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:16,654] Trial 80 finished with value: 0.9222222222222223 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:16,960] Trial 81 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:17,266] Trial 82 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:17,576] Trial 83 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:17,881] Trial 84 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:17,916] Trial 85 finished with value: 0.9222222222222223 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:17,947] Trial 86 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:18,246] Trial 87 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'ball_tree', 'p': 1}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:18,616] Trial 88 finished with value: 0.9305555555555556 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:18,922] Trial 89 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:19,233] Trial 90 finished with value: 0.9222222222222223 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:19,538] Trial 91 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:19,851] Trial 92 finished with value: 0.9 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:20,162] Trial 93 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:20,472] Trial 94 finished with value: 0.9222222222222223 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:20,767] Trial 95 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:21,130] Trial 96 finished with value: 0.9388888888888889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:21,440] Trial 97 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:21,751] Trial 98 finished with value: 0.9222222222222223 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n",
      "[I 2024-11-04 01:12:22,061] Trial 99 finished with value: 0.9138888888888889 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'p': 2}. Best is trial 11 with value: 0.9388888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Bayesian Optimization tuning. Time taken: 26.82 seconds\n",
      "\n",
      "Best parameters for KNN (Bayesian Optimization):\n",
      "n_neighbors: 1\n",
      "weights: uniform\n",
      "algorithm: ball_tree\n",
      "p: 2\n",
      "Best accuracy: 0.9389\n",
      "\n",
      "Number of training samples: 840\n",
      "Number of testing samples: 360\n",
      "Total samples: 1200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from deap import base, creator, tools, algorithms\n",
    "import optuna\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the parameter spaces for SVM and KNN\n",
    "param_space = {\n",
    "    'svm': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto'] + [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "        'degree': [2, 3, 4, 5]  # Only used when kernel='poly'\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': list(range(1, 31)),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'p': [1, 2]  # 1 for manhattan_distance, 2 for euclidean_distance\n",
    "    }\n",
    "}\n",
    "\n",
    "def prepare_data(X, y, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=360, train_size=840, stratify=y, random_state=random_state)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "def genetic_algorithm(X, y, classifier_type, random_state=42):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = prepare_data(X, y, random_state)\n",
    "\n",
    "    def evaluate(individual):\n",
    "        if classifier_type == 'svm':\n",
    "            clf = SVC(\n",
    "                C=individual[0],\n",
    "                kernel=individual[1],\n",
    "                gamma=individual[2],\n",
    "                degree=individual[3] if individual[1] == 'poly' else 3,\n",
    "                random_state=random_state\n",
    "            )\n",
    "        else:  # KNN\n",
    "            clf = KNeighborsClassifier(\n",
    "                n_neighbors=individual[0],\n",
    "                weights=individual[1],\n",
    "                algorithm=individual[2],\n",
    "                p=individual[3]\n",
    "            )\n",
    "        \n",
    "        try:\n",
    "            clf.fit(X_train_scaled, y_train)\n",
    "            y_pred = clf.predict(X_test_scaled)\n",
    "            return accuracy_score(y_test, y_pred),\n",
    "        except Exception as e:\n",
    "            print(f\"Error during evaluation: {e}\")\n",
    "            return 0,\n",
    "\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    if classifier_type == 'svm':\n",
    "        toolbox.register(\"attr_C\", random.choice, param_space['svm']['C'])\n",
    "        toolbox.register(\"attr_kernel\", random.choice, param_space['svm']['kernel'])\n",
    "        toolbox.register(\"attr_gamma\", random.choice, param_space['svm']['gamma'])\n",
    "        toolbox.register(\"attr_degree\", random.choice, param_space['svm']['degree'])\n",
    "    else:  # KNN\n",
    "        toolbox.register(\"attr_n_neighbors\", random.choice, param_space['knn']['n_neighbors'])\n",
    "        toolbox.register(\"attr_weights\", random.choice, param_space['knn']['weights'])\n",
    "        toolbox.register(\"attr_algorithm\", random.choice, param_space['knn']['algorithm'])\n",
    "        toolbox.register(\"attr_p\", random.choice, param_space['knn']['p'])\n",
    "\n",
    "    toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                     (toolbox.attr_C, toolbox.attr_kernel, toolbox.attr_gamma, toolbox.attr_degree) if classifier_type == 'svm'\n",
    "                     else (toolbox.attr_n_neighbors, toolbox.attr_weights, toolbox.attr_algorithm, toolbox.attr_p),\n",
    "                     n=1)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=10, indpb=0.2)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population(n=50)\n",
    "    ngen = 10\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f\"Starting Genetic Algorithm optimization for {classifier_type.upper()}...\")\n",
    "\n",
    "    result, log = algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=ngen, verbose=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Finished Genetic Algorithm tuning. Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    best_individual = tools.selBest(result, k=1)[0]\n",
    "    if classifier_type == 'svm':\n",
    "        best_params = {\n",
    "            'C': best_individual[0],\n",
    "            'kernel': best_individual[1],\n",
    "            'gamma': best_individual[2],\n",
    "            'degree': best_individual[3] if best_individual[1] == 'poly' else 3\n",
    "        }\n",
    "    else:  # KNN\n",
    "        best_params = {\n",
    "            'n_neighbors': best_individual[0],\n",
    "            'weights': best_individual[1],\n",
    "            'algorithm': best_individual[2],\n",
    "            'p': best_individual[3]\n",
    "        }\n",
    "    best_accuracy = best_individual.fitness.values[0]\n",
    "\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "def bayesian_optimization(X, y, classifier_type, random_state=42):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = prepare_data(X, y, random_state)\n",
    "\n",
    "    def objective(trial):\n",
    "        if classifier_type == 'svm':\n",
    "            params = {\n",
    "                'C': trial.suggest_categorical('C', param_space['svm']['C']),\n",
    "                'kernel': trial.suggest_categorical('kernel', param_space['svm']['kernel']),\n",
    "                'gamma': trial.suggest_categorical('gamma', param_space['svm']['gamma']),\n",
    "                'random_state': random_state\n",
    "            }\n",
    "            if params['kernel'] == 'poly':\n",
    "                params['degree'] = trial.suggest_int('degree', 2, 5)\n",
    "            clf = SVC(**params)\n",
    "        else:  # KNN\n",
    "            params = {\n",
    "                'n_neighbors': trial.suggest_int('n_neighbors', 1, 30),\n",
    "                'weights': trial.suggest_categorical('weights', param_space['knn']['weights']),\n",
    "                'algorithm': trial.suggest_categorical('algorithm', param_space['knn']['algorithm']),\n",
    "                'p': trial.suggest_categorical('p', param_space['knn']['p'])\n",
    "            }\n",
    "            clf = KNeighborsClassifier(**params)\n",
    "        \n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f\"Starting Bayesian Optimization for {classifier_type.upper()}...\")\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Finished Bayesian Optimization tuning. Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_accuracy = study.best_value\n",
    "\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "# Main execution\n",
    "random_state = 42\n",
    "\n",
    "# Assuming X and y are your feature matrix and target vector\n",
    "# X = ...\n",
    "# y = ...\n",
    "\n",
    "for classifier_type in ['svm', 'knn']:\n",
    "    print(f\"\\nEvaluating {classifier_type.upper()}\")\n",
    "    \n",
    "    print(\"Genetic Algorithm Optimization\")\n",
    "    ga_best_params, ga_best_accuracy = genetic_algorithm(X, y, classifier_type, random_state=random_state)\n",
    "    print(f\"\\nBest parameters for {classifier_type.upper()} (Genetic Algorithm):\")\n",
    "    for param, value in ga_best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    print(f\"Best accuracy: {ga_best_accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\nBayesian Optimization\")\n",
    "    bo_best_params, bo_best_accuracy = bayesian_optimization(X, y, classifier_type, random_state=random_state)\n",
    "    print(f\"\\nBest parameters for {classifier_type.upper()} (Bayesian Optimization):\")\n",
    "    for param, value in bo_best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    print(f\"Best accuracy: {bo_best_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nNumber of training samples: 840\")\n",
    "print(f\"Number of testing samples: 360\")\n",
    "print(f\"Total samples: 1200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9c8ed-f27f-4d05-8b14-b7bd3dba9776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8494e420-5679-44ee-a97e-bf6f9cadfc78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
